{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iGED : Global Systems Dynamics Initiative\n",
    "\n",
    "El objetivo principal de este documento es analizar las métricas globales en las siguientes redes capitales\n",
    "\n",
    "  *  Ciudad Autónoma de Buenos Aires (CABA)\n",
    "  *  Ciudad de México (CDMX)\n",
    "  *  Santiago de Chile (SCL)\n",
    "  *  Montevideo (MTV)\n",
    "  *  Madrid (MAD)\n",
    "  *  Sao Paulo (SAO)\n",
    "\n",
    "y obtener un tidy DataFrame, para continuar analizando los datos obtenidos, por ejemplo obteniendo correlaciones entre parejas de métricas.\n",
    "\n",
    "Respecto al notebook anterior, utilizamos la documentación de NetworkX: https://www.nas.ewi.tudelft.nl/people/Piet/papers/TUDreport20111111_MetricList.pdf\n",
    "\n",
    "así como el siguiente recurso: https://www.nas.ewi.tudelft.nl/people/Piet/papers/TUDreport20111111_MetricList.pdf\n",
    "\n",
    "para saber con cuáles métricas globales seguir estudiando nuestros ecosistemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------\n",
    "# Importar paquetes a utilizar\n",
    "#-------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import networkx as nx\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "#in this dictionary we collect the information for the 200 random graphs we generated\n",
    "G={'Nuevas_Conexiones':[],'Numero_Respuestas':[], 'Rango_Respondientes':[], 'Respondientes':[]}\n",
    "\n",
    "for key in G.keys():\n",
    "    for i in range(200):\n",
    "        G[key].append(nx.read_graphml('Random_Graphs_'+key+'/Random_Graph_'+key+str(i)+'.graphml'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# Central point of Dominance\n",
    "#--------------------------------\n",
    "# How centralized a graph is with respect to the metric betweenness centrality.\n",
    "\n",
    "def central_point_dominance(G):\n",
    "    betwennesses = nx.betweenness_centrality(G)\n",
    "    b_max = max(betwennesses.values())\n",
    "    N = len(betwennesses.keys())\n",
    "    count = 0\n",
    "    for i, b_i in betwennesses.items():\n",
    "        count += ( b_max - b_i )/(N-1)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# Spectral Radius\n",
    "#--------------------------------\n",
    "#     the smaller the spectral radius rho, the higher the probability of 'virus infection' tau, \n",
    "#     the more difficult it is for an idea to spread in the innovative network, \n",
    "#     namely, the less efficient\n",
    "\n",
    "import numpy.linalg\n",
    "\n",
    "def spectral_radius(G):\n",
    "    L = nx.normalized_laplacian_matrix(G)\n",
    "    e = numpy.linalg.eigvals(L.A)\n",
    "    e_abs = [abs(x) for x in e]\n",
    "    return max(e_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_ratio(G):\n",
    "    return len(nx.k_core(G,k=2).nodes())/len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rich_club_coeffs(G):\n",
    "    t_ok = True\n",
    "    t = 0\n",
    "    d = dict()\n",
    "    while t_ok:\n",
    "        nodes_large_degree=[]\n",
    "        for x in G.nodes():\n",
    "            if G.degree(x)>t:\n",
    "                nodes_large_degree.append(x)\n",
    "        core = G.subgraph(nodes_large_degree)\n",
    "        edges_core = len(core.edges())\n",
    "        nodes_core = len(core.nodes())\n",
    "        if nodes_core<=1:\n",
    "            t_ok = False\n",
    "            break\n",
    "        d[t] = (2*edges_core)/(nodes_core*(nodes_core-1))\n",
    "        t += 1 \n",
    "    return d        \n",
    "\n",
    "def max_rich_club(G):\n",
    "    #rich_club_1=nx.algorithms.rich_club_coefficient(G, normalized=False)\n",
    "    rich_club=rich_club_coeffs(G)\n",
    "    max_i=0\n",
    "    for i in range(len(rich_club)):\n",
    "        if rich_club[i]>rich_club[max_i]:\n",
    "            max_i=i\n",
    "        else:\n",
    "            return rich_club[max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eccentricity(G):\n",
    "    excentricidades=nx.algorithms.distance_measures.eccentricity(G)\n",
    "    excentricidad=0\n",
    "    for i in excentricidades.keys():\n",
    "        excentricidad+=excentricidades[i]\n",
    "    return excentricidad/len(excentricidades.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_responses(G):\n",
    "    avg=0\n",
    "    respondents=0\n",
    "    for node in G.nodes:\n",
    "        try:\n",
    "            avg+= node['responses']\n",
    "            respondents+=0\n",
    "        except:\n",
    "            pass\n",
    "    if respondents==0:\n",
    "        return 0\n",
    "    return avg/respondents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree(G):\n",
    "    return 2*len(G.edges())/len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity(G):\n",
    "    nx.algorithms.community.quality.performance(G,nx.algorithms.community.modularity_max.greedy_modularity_communities(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion del Dataframe\n",
    "\n",
    "El siguiente bloque crea todas las metricas de la grafica que usaremos para estudiarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_function_map = {'Degree': degree,\n",
    "            'Excentricidad': eccentricity,\n",
    "            'Diametro': nx.diameter,\n",
    "            'Radio':nx.radius,\n",
    "            'Camino más corto promedio':nx.average_shortest_path_length,\n",
    "            'Transitividad':nx.transitivity,\n",
    "            'Eficiencia Global':nx.global_efficiency,\n",
    "            'Rich Club Coefficient':max_rich_club,\n",
    "            'Core Ratio':core_ratio,\n",
    "            'Central Point Dominance':central_point_dominance,\n",
    "            'Spectral radius':spectral_radius,\n",
    "            'Modularidad':modularity\n",
    "            'Average Collaborations': responses}\n",
    "\n",
    "def measures(G):\n",
    "    D = dict()\n",
    "    for metric, function in metric_function_map.items():\n",
    "        D[metric] = [function(nx.to_undirected(G))]\n",
    "    return D\n",
    "\n",
    "def embed(D1, D2):\n",
    "    for key, value in D1.items():\n",
    "        D2[key].append(value)\n",
    "    return D2\n",
    "\n",
    "def df_colaboraciones_test(keys,n=200):\n",
    "    \"\"\"\n",
    "    keys es una lista de los atributos que queremos leer\n",
    "    \"\"\"\n",
    "\n",
    "    dfs={}\n",
    "\n",
    "    for key in keys:\n",
    "\n",
    "        for index in range(n):\n",
    "            graph=G[key][index]\n",
    "            if index==0:\n",
    "                dict_meas=measures(graph)\n",
    "            new=measures(graph)\n",
    "            for metric in metric_function_map.keys():\n",
    "                dict_meas[metric]+=new[metric]\n",
    "\n",
    "        dfs[key]=pd.DataFrame()\n",
    "        for metric in metric_function_map.keys():\n",
    "            dfs[key][metric]=dict_meas[metric]\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-9-7811093adf6c>, line 5)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-7811093adf6c>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def df_colaboraciones_test(keys):\n",
    "    \"\"\"\n",
    "    #keys es una lista de los atributos que queremos leer\n",
    "    \"\"\"\n",
    "\n",
    "    n=200\n",
    "\n",
    "    degree = {}\n",
    "    diameter = {}\n",
    "    radius = {}\n",
    "    avg_shortest_path_length = {}\n",
    "    transitivity = {}\n",
    "    global_efficiency = {}\n",
    "    modularity = {}\n",
    "    rich_club_coefficient = {}\n",
    "    core_rate= {}\n",
    "    central_pt = {}\n",
    "    spectral_radii = {}\n",
    "    excentricidad = {}\n",
    "    modularidad = {}\n",
    "    responses = {}\n",
    "\n",
    "    dfs={}\n",
    "\n",
    "    for key in keys:\n",
    "\n",
    "        degree[key] = n*[0]\n",
    "        diameter[key] = n*[0]\n",
    "        radius[key] = n*[0]\n",
    "        avg_shortest_path_length[key] = n*[0]\n",
    "        transitivity[key] = n*[0]\n",
    "        global_efficiency[key] = n*[0]\n",
    "        modularity[key] = n*[0]\n",
    "        rich_club_coefficient[key] = n*[0]\n",
    "        core_rate[key]= n*[0]\n",
    "        central_pt[key] = n*[0]\n",
    "        spectral_radii[key] = n*[0]\n",
    "        excentricidad[key] = n*[0]\n",
    "        modularidad[key] = n*[0]\n",
    "        responses[key] = n*[0]\n",
    "\n",
    "        for index in range(n):\n",
    "            graph=G[key][index]\n",
    "        \n",
    "            #conseguimos cada parámetro para esta ciudad\n",
    "            degree[key][index]=                        2*len(graph.edges())/len(graph.nodes())\n",
    "            diameter[key][index] =                     nx.diameter(graph)\n",
    "            radius[key][index] =                       nx.radius(graph)\n",
    "            avg_shortest_path_length[key][index] =     nx.average_shortest_path_length(graph)\n",
    "            transitivity[key][index] =                 nx.transitivity(graph)\n",
    "            global_efficiency[key][index] =            nx.global_efficiency(graph)\n",
    "            #modularidad precomputada\n",
    "            rich_club_coefficient[key][index] =        max_rich_club(graph)  \n",
    "            core_rate[key][index]=                     core_ratio(graph)\n",
    "            central_pt[key][index]=                    central_point_dominance(graph)\n",
    "            spectral_radii[key][index]=                spectral_radius(graph)\n",
    "            excentricidad[key][index]=                 eccentricity(graph)\n",
    "            modularidad[key][index]=                   nx.algorithms.community.quality.performance(graph,nx.algorithms.community.modularity_max.greedy_modularity_communities(graph))\n",
    "            responses[key][index]=                     avg_responses(graph)\n",
    "\n",
    "        dfs[key]=pd.DataFrame()\n",
    "\n",
    "        dfs[key]['Eficiencia Global'] = global_efficiency[key]\n",
    "        dfs[key]['Average Responses'] = responses[key]\n",
    "        dfs[key]['Degree']= degree[key]\n",
    "        dfs[key]['Transitividad'] = transitivity[key]\n",
    "        dfs[key]['Modularidad'] = modularidad[key]\n",
    "        dfs[key]['Excentricidad']= excentricidad[key]\n",
    "        dfs[key]['Radio'] = radius[key]\n",
    "        dfs[key]['Rich Club Coefficient'] = rich_club_coefficient[key]\n",
    "        dfs[key]['Core Ratio'] = core_rate[key]\n",
    "        dfs[key]['Central Point Dominance'] = [round(central_pt[key][index],3) for index in range(n)]\n",
    "        dfs[key]['Spectral radius'] = [round(spectral_radii[key][index],3) for index in range(n)]\n",
    "        dfs[key]['Camino más corto promedio'] = avg_shortest_path_length[key]\n",
    "        dfs[key]['Diámetro'] = diameter[key]\n",
    "\n",
    "    return dfs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colaboracion\n",
    "\n",
    "Empezamos analizando las metricas que ya hemos calculado y luego usaremos esta informacion para crear una medida de la colaboracion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_colaboraciones_test(['Nuevas_Conexiones'])['Nuevas_Conexiones'].to_csv('Random_Nuevas_Conexiones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Degree  Excentricidad  Diametro  Radio  Camino más corto promedio  \\\n0  3.378571            5.4         6      4                   3.861623   \n\n   Transitividad  Eficiencia Global  Rich Club Coefficient  Core Ratio  \\\n0       0.030827           0.285958                0.01211    0.503571   \n\n   Central Point Dominance  Spectral radius Modularidad  \n0                 0.148803         1.913123        None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Degree</th>\n      <th>Excentricidad</th>\n      <th>Diametro</th>\n      <th>Radio</th>\n      <th>Camino más corto promedio</th>\n      <th>Transitividad</th>\n      <th>Eficiencia Global</th>\n      <th>Rich Club Coefficient</th>\n      <th>Core Ratio</th>\n      <th>Central Point Dominance</th>\n      <th>Spectral radius</th>\n      <th>Modularidad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.378571</td>\n      <td>5.4</td>\n      <td>6</td>\n      <td>4</td>\n      <td>3.861623</td>\n      <td>0.030827</td>\n      <td>0.285958</td>\n      <td>0.01211</td>\n      <td>0.503571</td>\n      <td>0.148803</td>\n      <td>1.913123</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'dfs' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-384e73a86c86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mnormalized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfs' is not defined"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------\n",
    "#Preparar escalas y herramientas para el analisis.\n",
    "#---------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X={}\n",
    "normalized={}\n",
    "pca={}\n",
    "prin_comp={}\n",
    "\n",
    "for key in G.keys():\n",
    "    X[key]=dfs[key].to_numpy()\n",
    "\n",
    "    normalized[key]= StandardScaler().fit_transform(X[key])\n",
    "    pca[key]=PCA(n_components=5)\n",
    "    prin_comp[key]=pca.fit_transform(normalized[key])\n",
    "\n",
    "    print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Nuevas_Conexiones\n"
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'Nuevas_Conexiones'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f70538410a82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprin_comp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprin_comp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'Nuevas_Conexiones'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for key in G.keys():\n",
    "    print(key)\n",
    "    plt.scatter(prin_comp[key][:,0], prin_comp[key][:,1],color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Formulas de Colaboracion\"\"\"\n",
    "\n",
    "def colaborativity_original(df):\n",
    "    '''\n",
    "    Original Collaborativity Formula during summer 2020 for project GED.\n",
    "    Computes the colaborativity of a network G based on its measures, as shown below. \n",
    "    \n",
    "    Input:\n",
    "    - df : dataframe mapping each city to its graph metrics\n",
    "    Returns:\n",
    "    - Value describing the collaborativity of a graph, or network\n",
    "    '''\n",
    "    Avg_colabs =df['Average collabs']\n",
    "    Clust = df['Clustering']\n",
    "    Mod = df['Modularidad']\n",
    "    return (1/2) * Avg_colabs * (Clust + (np.log10(Mod**2)*-1))\n",
    "\n",
    "\n",
    "def colaborativity_formula_1(df):\n",
    "    Efi = df['Eficiencia Global']\n",
    "    Tran = df['Transitividad']\n",
    "    Mod = df['Modularidad']\n",
    "    Core = df['Core Ratio']\n",
    "    return Efi + Tran + 1 - (Mod + Core)/2 \n",
    "\n",
    "\n",
    "def colaborativity_formula_2(df):\n",
    "    Efi = df['Eficiencia Global']\n",
    "    Tran = df['Transitividad']\n",
    "    Exc = df['Excentricidad']\n",
    "    Mod = df['Modularidad']\n",
    "    return Efi + Tran + (1/Exc) - Mod\n",
    "\n",
    "\n",
    "def colaborativity_formula_3(df):\n",
    "    efi = df['Eficiencia Global']   #comunicacion\n",
    "    clus = df['Clustering']         #robustez\n",
    "    mod = df['Modularidad']          #preparación para el futuro \n",
    "    return (efi * clus * (1+np.cos(math.pi*mod)) /2 )**(1/3)\n",
    "\n",
    "\n",
    "def colaborativity_formula_4(df):\n",
    "    efi = df['Eficiencia Global']    #comunicacion \n",
    "    tran = df['Transitividad']       #robustez\n",
    "    mod = df['Modularidad']           #preparación para el futuro \n",
    "    return (efi * tran * (1+np.cos(math.pi*mod)) /2 )**(1/3)\n",
    "\n",
    "\n",
    "def colaborativity_formula_5(df):\n",
    "    efi = df['Eficiencia Global']    #comunicacion \n",
    "    tran = df['Transitividad']       #robustez\n",
    "    core = df['Core Ratio']           #preparación para el futuro \n",
    "    return efi + tran + 1 - core \n",
    "\n",
    "\n",
    "def colaborativity_formula_6(df):\n",
    "    efi = df['Eficiencia Global']    #comunicacion \n",
    "    tran = df['Transitividad']       #robustez\n",
    "    exc = df['Excentricidad']        #preparación para el futuro \n",
    "    return (efi * tran * (np.sin(math.pi/exc)) )**(1/3)\n",
    "\n",
    "\n",
    "# N e w    i d e a s    f o r   f o r m u l a s #\n",
    "\n",
    "def colaborativity_formula_7(df):\n",
    "    avg_deg = df['Average collabs']  #1 cantidad  \n",
    "    efi = df['Eficiencia Global']    #2 calidad   comunicacion \n",
    "    tran = df['Transitividad']       #            robustez\n",
    "    exc = df['Excentricidad']        #preparación para el futuro \n",
    "    return 0.5*(np.log10(avg_deg+1)/np.log10(26))  +  0.5*quadratic([efi , tran , (np.sin(math.pi/exc))])\n",
    "\n",
    "\n",
    "def colaborativity_formula_8(df):\n",
    "    avg_deg = df['Average collabs']  #1 cantidad  \n",
    "    efi = df['Eficiencia Global']    #2 calidad   comunicacion \n",
    "    tran = df['Transitividad']       #            robustez\n",
    "    mod = df['Modularidad']        #preparación para el futuro \n",
    "    return 0.5*(np.log10(avg_deg+1)/np.log10(26)) + 0.5*quadratic([efi , tran , 0.5*(1+np.cos(math.pi*mod)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'colaborativity_formula_0' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7a979ea9eb0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcolaborativity_formulas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcolaborativity_formulas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'colaborativity_formula_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'colaborativity_formula_0' is not defined"
     ]
    }
   ],
   "source": [
    "#---------------------------------------\n",
    "# Fórmula para colaboratividad\n",
    "#---------------------------------------\n",
    "\n",
    "colaborativity_formulas={}\n",
    "for i in range(9):\n",
    "    colaborativity_formulas[i]=eval('colaborativity_formula_'+str(i))\n",
    "\n",
    "for key in G.keys():\n",
    "    for i in range(9):\n",
    "\n",
    "        colab={}\n",
    "\n",
    "        colaboration_results=colaborativity_formulas[i](df[key])\n",
    "        colab[key] = {colaboration_results[x]:x for x in range(200)}\n",
    "        order_colab=list(colab[key].keys())\n",
    "        order_colab.sort()\n",
    "        ratio=0\n",
    "        print(key, i)\n",
    "        for i in range(40):\n",
    "            if colab[order_colab[i]]<101:\n",
    "                ratio+=1\n",
    "        ratio/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'colab' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e7c574dfe3ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0morder_colab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'colab' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print(colab[order_colab[i]])"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}