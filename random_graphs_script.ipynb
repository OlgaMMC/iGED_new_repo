{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "def random_graph(prob_resp,prob_nuevo):\n",
    "    \"\"\"\n",
    "    prob_resp float    define la probabilidad de que al tomar un nodo este haya sido un respondiente de la encuesta\n",
    "    prob_nuevo float   define la probabilidad de que un respondiente tenga conexiones con nodos nuevos\n",
    "\n",
    "    Esta funcion genera graficas aleatorias basadas en el metodo con el que se crearon las networks de emprendimiento\n",
    "    \"\"\"\n",
    "    G=nx.Graph()\n",
    "    queue=[\"0\"]\n",
    "    max_index=0\n",
    "    max_respondents=random.randint(20,30)             #Indicador que nos dice cuantos respondientes puede haber\n",
    "    respondents=0\n",
    "    while len(queue)!=0:\n",
    "        if (random.random()<prob_resp and respondents<max_respondents) or queue[0]==\"0\":      #Crear conexiones para un respondiente\n",
    "            respondents+=1\n",
    "            n=random.randint(6,21)\n",
    "            new_n=0\n",
    "            old_n=0\n",
    "            for i in range(n):                                              #Calcular cuantas conexiones son con nodos nuevos y cuantos con ya existentesz\n",
    "                if random.random()<prob_nuevo:\n",
    "                    new_n+=1\n",
    "                else:\n",
    "                    old_n+=1\n",
    "            for i in range(new_n):\n",
    "                new_node=str(i+max_index+1)\n",
    "                queue.append(new_node)\n",
    "                G.add_node(new_node)\n",
    "                G.add_edge(queue[0],new_node)\n",
    "            for i in range(old_n):\n",
    "                node=str(random.randint(0,int(queue[0]))-1)\n",
    "                G.add_edge(queue[0],node)\n",
    "            max_index+=new_n\n",
    "            queue.pop(0)\n",
    "        else:                                                                #Crear conexiones para los no respondientes\n",
    "            if random.random()<0.25:\n",
    "                n=random.randint(1,6)\n",
    "                for i in range(n):\n",
    "                    node=str(random.randint(0,int(queue[0]))-1)\n",
    "                    G.add_edge(queue[0],node)\n",
    "            queue.pop(0)\n",
    "    return G\n",
    "    \n",
    "G1 = random_graph(0.25,0.55)\n",
    "G2 = random_graph(0.25,0.55)\n",
    "G3 = random_graph(0.25,0.55)\n",
    "G4 = random_graph(0.25,0.55)\n",
    "G5 = random_graph(0.25,0.55)\n",
    "G6 = random_graph(0.25,0.55)\n",
    "G7 = random_graph(0.25,0.55)\n",
    "G8 = random_graph(0.25,0.55)\n",
    "G9 = random_graph(0.25,0.55)\n",
    "G10 = random_graph(0.25,0.55)\n",
    "#nx.write_graphml(G1,'Random_Graphs/Random_Graph_1.graphml')\n",
    "#nx.write_graphml(G2,'Random_Graphs/Random_Graph_2.graphml')\n",
    "#nx.write_graphml(G3,'Random_Graphs/Random_Graph_3.graphml')\n",
    "#nx.write_graphml(G4,'Random_Graphs/Random_Graph_4.graphml')\n",
    "#nx.write_graphml(G5,'Random_Graphs/Random_Graph_5.graphml')\n",
    "#nx.write_graphml(G6,'Random_Graphs/Random_Graph_6.graphml')\n",
    "#nx.write_graphml(G7,'Random_Graphs/Random_Graph_7.graphml')\n",
    "#nx.write_graphml(G8,'Random_Graphs/Random_Graph_8.graphml')\n",
    "#nx.write_graphml(G9,'Random_Graphs/Random_Graph_9.graphml')\n",
    "#nx.write_graphml(G10,'Random_Graphs/Random_Graph_10.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic(L):\n",
    "    return ( sum([x**2 for x in L])/len(L) )**0.5\n",
    "    \n",
    "def arithmetic(L):\n",
    "    return sum(L)/len(L)\n",
    "\n",
    "def geometric(L):\n",
    "    prod = 1\n",
    "    for x in L:\n",
    "        prod *=x\n",
    "    return prod**(1/len(L))\n",
    "\n",
    "def harmonic(L):\n",
    "    n = len(L)\n",
    "    sum_reciprocals = sum([1/x for x in L])\n",
    "    return n/sum_reciprocals\n",
    "\n",
    "\n",
    "mean_map = {'quadratic': quadratic, \n",
    "           'arithmetic': arithmetic, \n",
    "           'geometric': geometric, \n",
    "           'harmonic': harmonic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------\n",
    "# Graph metrics!\n",
    "#-----------------------\n",
    "\n",
    "def degree(G):\n",
    "    return np.mean([G.degree(x) for x in G.nodes()])\n",
    "\n",
    "def eccentricity(U):\n",
    "    return np.mean([nx.eccentricity(U,x) for x in U.nodes()])\n",
    "\n",
    "def clustering(U):\n",
    "    return np.mean([nx.clustering(U,x) for x in U.nodes()]) \n",
    "\n",
    "def diameter(U):\n",
    "    return nx.diameter(U)\n",
    "\n",
    "def radius(U):\n",
    "    return nx.radius(U)\n",
    "\n",
    "def avg_shortest_path_length(U):\n",
    "    return nx.average_shortest_path_length(U)\n",
    "\n",
    "def transitivity(U):\n",
    "    return nx.transitivity(U)\n",
    "\n",
    "def global_efficiency(U):\n",
    "    return nx.global_efficiency(U)\n",
    "\n",
    "def small_worldness(U):\n",
    "    return nx.algorithms.smallworld.sigma(U,niter=1,nrand=2)\n",
    "\n",
    "def rich_club_coeffs(G):\n",
    "    t_ok = True\n",
    "    t = 0\n",
    "    d = dict()\n",
    "    while t_ok:\n",
    "        nodes_large_degree=[]\n",
    "        for x in G.nodes():\n",
    "            if G.degree(x)>t:\n",
    "                nodes_large_degree.append(x)\n",
    "        core = G.subgraph(nodes_large_degree)\n",
    "        edges_core = len(core.edges())\n",
    "        nodes_core = len(core.nodes())\n",
    "        if nodes_core<=1:\n",
    "            t_ok = False\n",
    "            break\n",
    "        d[t] = (2*edges_core)/(nodes_core*(nodes_core-1))\n",
    "        t += 1 \n",
    "    return d  \n",
    "\n",
    "def max_rich_club(G):\n",
    "    rich_club=rich_club_coeffs(G)\n",
    "    max_i=0\n",
    "    \n",
    "    for i in range(len(rich_club)):\n",
    "        if rich_club[i]>rich_club[max_i]:\n",
    "            max_i=i\n",
    "    return rich_club[max_i]\n",
    "\n",
    "def core_ratio(G):\n",
    "    return len(nx.k_core(G,k=2).nodes())/len(G.nodes())\n",
    "        \n",
    "def central_point_dominance(G):\n",
    "    betwennesses = nx.betweenness_centrality(G)\n",
    "    b_max = max(betwennesses.values())\n",
    "    N = len(betwennesses.keys())\n",
    "    count = 0\n",
    "    for i, b_i in betwennesses.items():\n",
    "        count += ( b_max - b_i )/(N-1)\n",
    "    return count\n",
    "\n",
    "\n",
    "def spectral_radius(G):\n",
    "    L = nx.normalized_laplacian_matrix(G)\n",
    "    e = np.linalg.eigvals(L.A)\n",
    "    e_abs = [abs(x) for x in e]\n",
    "    return max(e_abs)\n",
    "\n",
    "def modularity(G):\n",
    "    return nx.algorithms.community.quality.performance(G,nx.algorithms.community.modularity_max.greedy_modularity_communities(G))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "metric_function_map = {'Degree': degree,\n",
    "            'Eccentricity': eccentricity,\n",
    "            'clustering': clustering,\n",
    "            'Diámetro': diameter,\n",
    "            'Radio':radius,\n",
    "            'Camino más corto promedio':avg_shortest_path_length,\n",
    "            'Transitividad':transitivity,\n",
    "            'Eficiencia Global':global_efficiency,\n",
    "            'Small Worldness':small_worldness,\n",
    "            'Rich Club Coefficient':max_rich_club,\n",
    "            'Core Ratio':core_ratio,\n",
    "            'Central Point Dominance':central_point_dominance,\n",
    "            'Spectral radius':spectral_radius,\n",
    "            'Modularidad':modularity} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "\n",
    "def are_adjacent(u,v,G):\n",
    "    if v not in G.nodes():\n",
    "        return False\n",
    "    #elif u in G.neighbors(v):\n",
    "    #    return True\n",
    "    elif v in G.neighbors(u):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def random_graph_2(n_evals, prob_out, prob_new):\n",
    "    '''\n",
    "    Generator of a random graph, given that n\n",
    "    Given a specific number of respondents of the questionnaire, and that each of them could have provided 25 responses maximum\n",
    "    \n",
    "    Input:\n",
    "     - n_evals  : number of evaluators responding questionnaire\n",
    "     - prob_out : probability that a mentionned collaboration is outside of the network of evaluators\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    G=nx.DiGraph()\n",
    "    setedges = set()\n",
    "    \n",
    "    inside = dict()\n",
    "    outside = dict()\n",
    "    \n",
    "    last_index = n_evals-1\n",
    "    \n",
    "    for i in range(n_evals):              #add all evaluators to the graph\n",
    "        G.add_node(i)\n",
    "        inside[i] = 0\n",
    "        \n",
    "    # evaluator |--> no. of collaborations,   in (0,25)~ normal distribution\n",
    "    sample_num_evaluations = np.random.normal(loc=12.3, scale=4, size=n_evals)\n",
    "    list_degrees_evaluators = [int(x) for x in sample_num_evaluations]\n",
    "    \n",
    "    for i in inside.keys():\n",
    "        for j in range(list_degrees_evaluators[i]):\n",
    "            \n",
    "            if random.random()<prob_out:           #edge added outside evaluators' list\n",
    "                if outside == dict():                              # if list outside evaluators is new\n",
    "                    last_index+=1\n",
    "                    to = last_index\n",
    "                    G.add_node(to)\n",
    "                    G.add_edge(i,to)\n",
    "                    setedges.add((i,to))\n",
    "                    outside[to] = 1\n",
    "                    inside[i] += 1\n",
    "                else:\n",
    "                    if random.random()<prob_new:               # if edge goes to a new vertex\n",
    "                        last_index+=1       \n",
    "                        to=last_index\n",
    "                        G.add_node(to)\n",
    "                        G.add_edge(i,to)\n",
    "                        setedges.add((i,to))\n",
    "                        outside[to] = 1\n",
    "                        inside[i] +=1\n",
    "                        \n",
    "                    else:\n",
    "                        vertices, degrees = [], []\n",
    "                        for vertex, degree in outside.items():\n",
    "                            if vertex!=i:\n",
    "                                vertices.append(vertex)\n",
    "                                degrees.append(degree+1)\n",
    "                        s = sum(degrees)\n",
    "                        w = [x/s for x in degrees]\n",
    "                        to = choice(vertices, size=1, p=w)[0]\n",
    "                        if are_adjacent(i,to,G):\n",
    "                            to = choice(vertices, size=1, p=w)[0]\n",
    "                        G.add_node(to)\n",
    "                        G.add_edge(i,to)\n",
    "                        setedges.add((i,to))\n",
    "                        outside[to]+=1\n",
    "                        inside[i]+=1\n",
    "                        \n",
    "            else:\n",
    "                vertices, degrees = [], []\n",
    "                for vertex, degree in inside.items():\n",
    "                    if vertex != i:\n",
    "                        vertices.append(vertex)\n",
    "                        degrees.append(degree+1)\n",
    "                s = sum(degrees)\n",
    "                w = [x/s for x in degrees]\n",
    "                to = choice(vertices, size=1, p=w)[0]\n",
    "                if are_adjacent(i,to,G):\n",
    "                    to = choice(vertices, size=1, p=w)[0]\n",
    "                G.add_node(to)\n",
    "                G.add_edge(i,to)\n",
    "                setedges.add((i,to))\n",
    "                inside[to]+=1\n",
    "                inside[i]+=1\n",
    "                \n",
    "    #print(n_evaluated_list)\n",
    "    #print('')\n",
    "    #print(G.nodes())\n",
    "    #print('')\n",
    "    #print(G.edges())\n",
    "    #print('')\n",
    "    #print([len(list(G.neighbors(x))) for x in G.nodes()])\n",
    "    return G         \n",
    "\n",
    "\n",
    "list_cities = ['Aguascalientes', 'Buenos Aires', 'Ciudad de México', 'Guadalajara', 'Hidalgo',\n",
    "                  'Madrid', 'Montevideo', 'Oaxaca', 'Sao Paulo', 'Santiago de Chile']\n",
    "num_evaluators = {'Aguascalientes':19, 'Buenos Aires':31, 'Ciudad de México':36, 'Guadalajara':32, 'Hidalgo':19,\n",
    "                  'Madrid':37, 'Montevideo':48, 'Oaxaca':36, 'Sao Paulo':28, 'Santiago de Chile':25}\n",
    "for city in list_cities:\n",
    "    G= random_graph_2(num_evaluators[city],0.2, 0.5)\n",
    "    nx.write_graphml(G,'Random_Graphs_Second_Type_Corrected/Random_Graph_'+city+'.graphml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Madrid</th>\n",
       "      <th>Madrid SG</th>\n",
       "      <th>Madrid Typeform</th>\n",
       "      <th>CDMX</th>\n",
       "      <th>Santiago</th>\n",
       "      <th>CABA</th>\n",
       "      <th>Sao Paulo</th>\n",
       "      <th>Montevideo</th>\n",
       "      <th>Oaxaca</th>\n",
       "      <th>GDL</th>\n",
       "      <th>Pachuca</th>\n",
       "      <th>AGS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muestra</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>59</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nodes</td>\n",
       "      <td>239</td>\n",
       "      <td>120</td>\n",
       "      <td>156</td>\n",
       "      <td>299</td>\n",
       "      <td>195</td>\n",
       "      <td>228</td>\n",
       "      <td>216</td>\n",
       "      <td>198</td>\n",
       "      <td>149</td>\n",
       "      <td>187</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Edges</td>\n",
       "      <td>453</td>\n",
       "      <td>166</td>\n",
       "      <td>205</td>\n",
       "      <td>547</td>\n",
       "      <td>385</td>\n",
       "      <td>500</td>\n",
       "      <td>364</td>\n",
       "      <td>767</td>\n",
       "      <td>326</td>\n",
       "      <td>474</td>\n",
       "      <td>254</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Promedio colabs. por participante</td>\n",
       "      <td>12.13</td>\n",
       "      <td>10.13</td>\n",
       "      <td>8.63</td>\n",
       "      <td>12.33</td>\n",
       "      <td>13.04</td>\n",
       "      <td>13.48</td>\n",
       "      <td>10.38</td>\n",
       "      <td>13.4</td>\n",
       "      <td>6.39</td>\n",
       "      <td>10.81</td>\n",
       "      <td>9.52</td>\n",
       "      <td>8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>% Muestra</td>\n",
       "      <td>15.90%</td>\n",
       "      <td>13.33%</td>\n",
       "      <td>15.38%</td>\n",
       "      <td>17.06%</td>\n",
       "      <td>15.38%</td>\n",
       "      <td>15.79%</td>\n",
       "      <td>15.74%</td>\n",
       "      <td>29.80%</td>\n",
       "      <td>24.16%</td>\n",
       "      <td>17.11%</td>\n",
       "      <td>16.80%</td>\n",
       "      <td>19.79%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Unnamed: 0  Madrid Madrid SG Madrid Typeform  \\\n",
       "0                            Muestra      38        16              24   \n",
       "1                              Nodes     239       120             156   \n",
       "2                              Edges     453       166             205   \n",
       "3  Promedio colabs. por participante   12.13     10.13            8.63   \n",
       "4                          % Muestra  15.90%    13.33%          15.38%   \n",
       "\n",
       "     CDMX Santiago    CABA Sao Paulo Montevideo  Oaxaca     GDL Pachuca  \\\n",
       "0      51       30      36        34         59      36      32      21   \n",
       "1     299      195     228       216        198     149     187     125   \n",
       "2     547      385     500       364        767     326     474     254   \n",
       "3   12.33    13.04   13.48     10.38       13.4    6.39   10.81    9.52   \n",
       "4  17.06%   15.38%  15.79%    15.74%     29.80%  24.16%  17.11%  16.80%   \n",
       "\n",
       "      AGS  \n",
       "0      19  \n",
       "1      96  \n",
       "2     233  \n",
       "3    8.21  \n",
       "4  19.79%  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muestra = pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - Muestra.csv')             \n",
    "\n",
    "\n",
    "ags_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - AGS.csv')             \n",
    "caba_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - CABA.csv')             \n",
    "cdmx_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - CDMX.csv')             \n",
    "gdl_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - GDL.csv')             \n",
    "hgo_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - HGO.csv')             \n",
    "mad_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - MAD.csv')             \n",
    "mtv_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - MVD.csv')             \n",
    "oax_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - OAX.csv')             \n",
    "sao_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - SAO.csv')             \n",
    "scl_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - SCL.csv')  \n",
    "\n",
    "ags_info.rename(columns={'Unnamed: 1':'Colabs'}, inplace=True)\n",
    "gdl_info.rename(columns={'Unnamed: 1':'Colabs'}, inplace=True)\n",
    "hgo_info.rename(columns={'Unnamed: 1':'Colabs'}, inplace=True)\n",
    "oax_info.rename(columns={'Unnamed: 1':'Colabs'}, inplace=True)\n",
    "\n",
    "\n",
    "list_cities = ['AGS', 'CABA', 'CDMX', 'GDL', 'Pachuca',\n",
    "                  'Madrid', 'Montevideo', 'Oaxaca', 'Sao Paulo', 'Santiago']\n",
    "cities_info = {'AGS': ags_info, \n",
    "              'CABA' : caba_info,\n",
    "              'CDMX' : cdmx_info,\n",
    "              'GDL' : gdl_info,\n",
    "              'Pachuca' : hgo_info,\n",
    "              'Madrid' : mad_info,\n",
    "              'Montevideo' : mtv_info,\n",
    "              'Oaxaca' : oax_info,\n",
    "              'Sao Paulo' : sao_info,\n",
    "              'Santiago' : scl_info}\n",
    "\n",
    "muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_graph(G):\n",
    "    '''\n",
    "    we make sure there are no nodes with   G.in_degree(x) , G.out_degree(x) == 0,0\n",
    "    '''\n",
    "    \n",
    "    to_remove = []\n",
    "    for x in G.nodes():\n",
    "        if G.in_degree(x) + G.out_degree(x) == 0:\n",
    "            to_remove.append(x)\n",
    "            #print('pinguito!')\n",
    "    #print(to_remove)\n",
    "    for x in to_remove:\n",
    "        G.remove_node(x)\n",
    "        #print('quitamos un pinguito')\n",
    "    for x in G.nodes():\n",
    "        if (G.in_degree(x), G.out_degree(x))==(0,0):\n",
    "            print('achis achis los mariachis')\n",
    "    #print('-----')\n",
    "    \n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eliminate_small_components(G):\n",
    "    '''\n",
    "    We make sure there are no disconnected components. \n",
    "    '''\n",
    "    to_remove = []\n",
    "    \n",
    "    for x in G.nodes():\n",
    "        if len(list(nx.node_connected_component(nx.to_undirected(G),x)))< 20 :\n",
    "            to_remove.append(x)\n",
    "    for x in to_remove:\n",
    "        G.remove_node(x)\n",
    "    \n",
    "    if nx.number_connected_components(nx.to_undirected(G))>1:\n",
    "        print('****')    \n",
    "    return G\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def random_graph_3(infos, city, prob_out, prob_new):\n",
    "    '''\n",
    "    With this function, we are simulating the responses we obtained from each of the surveyed ecosystems/cities. \n",
    "    The information we have is, for each evaluator, how many \n",
    "    \n",
    "    Generator of a random graph, given the number of respondents of the questionnaire,\n",
    "    the number of evaluators of collaborations, and the number of collaborations reported by each of them.\n",
    "    \n",
    "    Input:\n",
    "     - infos : dictionary mapping from city to num_collab information\n",
    "     - city : name of city to be simulated\n",
    "     - prob_out : probability that a mentionned collaboration is outside of the network of evaluators\n",
    "     - prob_new : probability that a mentionned collaboration is a newly mentionned org\n",
    "     \n",
    "    '''\n",
    "    \n",
    "    G=nx.DiGraph()\n",
    "    setedges = set()\n",
    "    \n",
    "    \n",
    "    #degrees of nodes inside and outside respondent list\n",
    "    inside = dict()\n",
    "    outside = dict()\n",
    "    \n",
    "    \n",
    "    #determine number of organizations that answered and number of evaluators: \n",
    "    n_responded = int(muestra[city][0])\n",
    "    n_evals = len(list(infos[city]['Colabs']))\n",
    "    last_index = n_responded\n",
    "    \n",
    "    \n",
    "    #number of total nodes, and number of edges:                  #still don't know how to use\n",
    "    num_nodes = int(muestra[city][1])\n",
    "    num_edges = int(muestra[city][2])\n",
    "    \n",
    "    for i in range(last_index):              #add all evaluators to the graph\n",
    "        G.add_node(i)\n",
    "        if i in range(n_evals):\n",
    "            inside[i] = 0\n",
    "        else:\n",
    "            outside[i] = 0\n",
    "        \n",
    "    \n",
    "    for i in inside.keys():\n",
    "        \n",
    "        deg_i = infos[city]['Colabs'][i]         # the degree of that node is in the info retrieved\n",
    "        for j in range(deg_i):\n",
    "            \n",
    "            if random.random() < prob_out:           #edge added outside evaluators' list\n",
    "                if outside == dict():                              # if list outside evaluators is new\n",
    "                    #last_index+=1\n",
    "                    to = last_index\n",
    "                    G.add_node(to)\n",
    "                    G.add_edge(i,to)\n",
    "                    setedges.add((i,to))\n",
    "                    outside[to] = 1\n",
    "                    inside[i] += 1\n",
    "                else:\n",
    "                    if random.random()<prob_new:               # if edge goes to a new vertex\n",
    "                        last_index+=1       \n",
    "                        to=last_index\n",
    "                        G.add_node(to)\n",
    "                        G.add_edge(i,to)\n",
    "                        setedges.add((i,to))\n",
    "                        outside[to] = 1\n",
    "                        inside[i] +=1\n",
    "                        \n",
    "                    else:\n",
    "                        vertices, degrees = [], []\n",
    "                        for vertex, degree in outside.items():\n",
    "                            if vertex!=i:\n",
    "                                vertices.append(vertex)\n",
    "                                degrees.append(degree+1)\n",
    "                        s = sum(degrees)\n",
    "                        w = [x/s for x in degrees]\n",
    "                        to = choice(vertices, size=1, p=w)[0]\n",
    "                        if are_adjacent(i,to,G):\n",
    "                            to = choice(vertices, size=1, p=w)[0]\n",
    "                        #G.add_node(to)\n",
    "                        G.add_edge(i,to)\n",
    "                        setedges.add((i,to))\n",
    "                        outside[to]+=1\n",
    "                        inside[i]+=1\n",
    "                        \n",
    "            else:\n",
    "                vertices, degrees = [], []\n",
    "                for vertex, degree in inside.items():\n",
    "                    if vertex != i:\n",
    "                        vertices.append(vertex)\n",
    "                        degrees.append(degree+1)\n",
    "                s = sum(degrees)\n",
    "                w = [x/s for x in degrees]\n",
    "                to = choice(vertices, size=1, p=w)[0]\n",
    "                if are_adjacent(i,to,G):\n",
    "                    to = choice(vertices, size=1, p=w)[0]\n",
    "                #G.add_node(to)\n",
    "                G.add_edge(i,to)\n",
    "                setedges.add((i,to))\n",
    "                inside[to]+=1\n",
    "                inside[i]+=1\n",
    "                \n",
    "    #now we have the degree of each evaluator covered, we covered some nodes outside of the evaluator set. \n",
    "    available_nodes = n_responded - n_evals\n",
    "    remaining_nodes = num_nodes - len(list(G.nodes()))\n",
    "    remaining_edges = num_edges - len(list(G.edges()))\n",
    "\n",
    "    #if remaining_nodes <= 0:\n",
    "    #    print('chinjoles')\n",
    "    #    return check_graph(G)\n",
    "    #if remaining_edges <= 0:\n",
    "    #    print('chinjoles')\n",
    "    #    return check_graph(G)\n",
    "    \n",
    "    #for i in range( last_index+1, num_nodes ):\n",
    "    #    G.add_node(i)\n",
    "    \n",
    "    for i in range(n_responded):\n",
    "        for j in range(2):\n",
    "\n",
    "            if random.random()<prob_out:           #edge added outside evaluators' list\n",
    "                if random.random()<prob_new:               # if edge goes to a new vertex\n",
    "                    last_index+=1       \n",
    "                    to=last_index\n",
    "                    G.add_node(to)\n",
    "                    G.add_edge(i,to)\n",
    "                    setedges.add((i,to))\n",
    "                    outside[to] = 1\n",
    "                    if i in outside.keys():\n",
    "                        outside[i]+=1  \n",
    "                    elif i in inside.keys():\n",
    "                        inside[i]+=1 \n",
    "                        \n",
    "                else:\n",
    "                    vertices, degrees = [], []\n",
    "                    for vertex, degree in outside.items():\n",
    "                        if vertex!=i:\n",
    "                            vertices.append(vertex)\n",
    "                            degrees.append(degree+1)\n",
    "                    s = sum(degrees)\n",
    "                    w = [x/s for x in degrees]\n",
    "                    to = choice(vertices, size=1, p=w)[0]\n",
    "                    if are_adjacent(i,to,G):\n",
    "                        to = choice(vertices, size=1, p=w)[0]\n",
    "                    #G.add_node(to)\n",
    "                    G.add_edge(i,to)\n",
    "                    setedges.add((i,to))\n",
    "                    outside[to]+=1\n",
    "                    if i in outside.keys():\n",
    "                        outside[i]+=1  \n",
    "                    elif i in inside.keys():\n",
    "                        inside[i]+=1 \n",
    "                        \n",
    "            else:\n",
    "                vertices, degrees = [], []\n",
    "                for vertex, degree in inside.items():\n",
    "                    if vertex != i:\n",
    "                        vertices.append(vertex)\n",
    "                        degrees.append(degree+1)\n",
    "                s = sum(degrees)\n",
    "                w = [x/s for x in degrees]\n",
    "                to = choice(vertices, size=1, p=w)[0]\n",
    "                if are_adjacent(i,to,G):\n",
    "                    to = choice(vertices, size=1, p=w)[0]\n",
    "                #G.add_node(to)\n",
    "                G.add_edge(i,to)\n",
    "                setedges.add((i,to))\n",
    "                inside[to]+=1\n",
    "                if i in outside.keys():\n",
    "                    outside[i]+=1  \n",
    "                elif i in inside.keys():\n",
    "                    inside[i]+=1  \n",
    "    \n",
    "    F=eliminate_small_components(G)\n",
    "    return F\n",
    "                \n",
    "            \n",
    "for city in list_cities:\n",
    "    G = random_graph_3(cities_info,city,0.8, 0.6)\n",
    "    nx.write_graphml(G,'Random_Graphs_Third_Type_Corrected/Random_Graph_'+city+'.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2943659618255683\n"
     ]
    }
   ],
   "source": [
    "def colaborativity(G, set_comunication, set_preparation, set_resilience, meantype):\n",
    "    '''\n",
    "    Computes the colaborativity of a network G based on sets which determine which metrics are to be computed\n",
    "    \n",
    "    - set_communication : set containing the names of the metrics that will measure communication pilar\n",
    "    - set_preparation : contains metrics that will measure preparation for future collabs pilar\n",
    "    - set_resilience : contins the names of the metrics that will measure resilience pilar\n",
    "    '''\n",
    "    comm, prep, resi = [], [], []\n",
    "    U = nx.to_undirected(G)\n",
    "    \n",
    "    for metric in set_communication:\n",
    "        comm.append( metric_function_map[metric](U) )\n",
    "    comm = arithmetic(comm)\n",
    "    \n",
    "    for metric in set_preparation:\n",
    "        prep.append( metric_function_map[metric](U) )\n",
    "    prep = arithmetic(prep)\n",
    "\n",
    "    \n",
    "    for metric in set_resilience:\n",
    "        resi.append( metric_function_map[metric](U) )\n",
    "    resi = arithmetic(resi)\n",
    "        \n",
    "    #now we compute the mean\n",
    "    \n",
    "    return mean_map[meantype]([comm, prep, resi])\n",
    "\n",
    "\n",
    "G = random_graph_3(cities_info,'GDL',0.8, 0.6)\n",
    "set_communication = {'Eficiencia Global'}\n",
    "set_preparation = {'Rich Club Coefficient'}\n",
    "set_resilience = {'Transitividad'}\n",
    "meantype = 'arithmetic'\n",
    "\n",
    "print(colaborativity(G, set_communication, set_preparation, set_resilience, meantype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colaborativity_from_dataframe(G, index, df, set_comunication, set_preparation, set_resilience, meantype):\n",
    "    '''\n",
    "    Computes the colaborativity of a network G based on sets which determine which metrics are to be computed\n",
    "    \n",
    "    - set_communication : set containing the names of the metrics that will measure communication pilar\n",
    "    - set_preparation : contains metrics that will measure preparation for future collabs pilar\n",
    "    - set_resilience : contins the names of the metrics that will measure resilience pilar\n",
    "    '''\n",
    "    comm, prep, resi = [], [], []\n",
    "    U = nx.to_undirected(G)\n",
    "    \n",
    "    for metric in set_communication:\n",
    "        comm.append( df[metric][index] )\n",
    "    comm = arithmetic(comm)\n",
    "    \n",
    "    for metric in set_preparation:\n",
    "        prep.append( df[metric][index] )\n",
    "    prep = arithmetic(prep)\n",
    "\n",
    "    \n",
    "    for metric in set_resilience:\n",
    "        resi.append( df[metric][index] )\n",
    "    resi = arithmetic(resi)\n",
    "        \n",
    "    #now we compute the mean\n",
    "    \n",
    "    return mean_map[meantype]([comm, prep, resi])\n",
    "\n",
    "\n",
    "G = random_graph_3(cities_info,'GDL',0.8, 0.6)\n",
    "set_communication = {'Eficiencia Global'}\n",
    "set_preparation = {'Rich Club Coefficient'}\n",
    "set_resilience = {'Transitividad'}\n",
    "meantype = 'arithmetic'\n",
    "\n",
    "#print(colaborativity(G, set_communication, set_preparation, set_resilience, meantype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Transitividad</th>\n",
       "      <th>Eficiencia Global</th>\n",
       "      <th>Small Worldness</th>\n",
       "      <th>Rich Club Coefficient</th>\n",
       "      <th>Core Ratio</th>\n",
       "      <th>Central Point Dominance</th>\n",
       "      <th>Spectral radius</th>\n",
       "      <th>Modularidad</th>\n",
       "      <th>Colaboratividad 1</th>\n",
       "      <th>Colaboratividad 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G0</td>\n",
       "      <td>3.50348</td>\n",
       "      <td>5.87471</td>\n",
       "      <td>0.0413817</td>\n",
       "      <td>0.290521</td>\n",
       "      <td>0.655481</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.417633</td>\n",
       "      <td>0.115607</td>\n",
       "      <td>1.859723</td>\n",
       "      <td>0.916538</td>\n",
       "      <td>0.343967</td>\n",
       "      <td>0.507654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G1</td>\n",
       "      <td>3.67476</td>\n",
       "      <td>5.8835</td>\n",
       "      <td>0.0394513</td>\n",
       "      <td>0.296965</td>\n",
       "      <td>0.601746</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>0.0963063</td>\n",
       "      <td>1.879433</td>\n",
       "      <td>0.931992</td>\n",
       "      <td>0.445472</td>\n",
       "      <td>0.567307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mean</td>\n",
       "      <td>3.58912</td>\n",
       "      <td>5.8791</td>\n",
       "      <td>0.0404165</td>\n",
       "      <td>0.293743</td>\n",
       "      <td>0.628613</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.417555</td>\n",
       "      <td>0.105956</td>\n",
       "      <td>1.869578</td>\n",
       "      <td>0.924265</td>\n",
       "      <td>0.394720</td>\n",
       "      <td>0.537480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Montevideo real</td>\n",
       "      <td>3    7.747475\n",
       "Name: Degree, dtype: float64</td>\n",
       "      <td>3    4.479798\n",
       "Name: Eccentricidad, dtype: float64</td>\n",
       "      <td>3    0.224523\n",
       "Name: Transitividad, dtype: float64</td>\n",
       "      <td>3    0.360837\n",
       "Name: Eficiencia Global, dtype: ...</td>\n",
       "      <td>3    1.274519\n",
       "Name: Small Worldness, dtype: fl...</td>\n",
       "      <td>3    1.0\n",
       "Name: Rich Club Coefficient, dtype: f...</td>\n",
       "      <td>3    0.565657\n",
       "Name: Core Ratio, dtype: float64</td>\n",
       "      <td>3    0.179\n",
       "Name: Central Point Dominance, dtyp...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3    0.611\n",
       "Name: Modularidad con pesos (1.0), ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name                                      Degree  \\\n",
       "0               G0                                     3.50348   \n",
       "1               G1                                     3.67476   \n",
       "2             Mean                                     3.58912   \n",
       "3  Montevideo real  3    7.747475\n",
       "Name: Degree, dtype: float64   \n",
       "\n",
       "                                        Eccentricity  \\\n",
       "0                                            5.87471   \n",
       "1                                             5.8835   \n",
       "2                                             5.8791   \n",
       "3  3    4.479798\n",
       "Name: Eccentricidad, dtype: float64   \n",
       "\n",
       "                                       Transitividad  \\\n",
       "0                                          0.0413817   \n",
       "1                                          0.0394513   \n",
       "2                                          0.0404165   \n",
       "3  3    0.224523\n",
       "Name: Transitividad, dtype: float64   \n",
       "\n",
       "                                   Eficiencia Global  \\\n",
       "0                                           0.290521   \n",
       "1                                           0.296965   \n",
       "2                                           0.293743   \n",
       "3  3    0.360837\n",
       "Name: Eficiencia Global, dtype: ...   \n",
       "\n",
       "                                     Small Worldness  \\\n",
       "0                                           0.655481   \n",
       "1                                           0.601746   \n",
       "2                                           0.628613   \n",
       "3  3    1.274519\n",
       "Name: Small Worldness, dtype: fl...   \n",
       "\n",
       "                               Rich Club Coefficient  \\\n",
       "0                                                0.7   \n",
       "1                                                  1   \n",
       "2                                               0.85   \n",
       "3  3    1.0\n",
       "Name: Rich Club Coefficient, dtype: f...   \n",
       "\n",
       "                                       Core Ratio  \\\n",
       "0                                        0.417633   \n",
       "1                                        0.417476   \n",
       "2                                        0.417555   \n",
       "3  3    0.565657\n",
       "Name: Core Ratio, dtype: float64   \n",
       "\n",
       "                             Central Point Dominance  Spectral radius  \\\n",
       "0                                           0.115607         1.859723   \n",
       "1                                          0.0963063         1.879433   \n",
       "2                                           0.105956         1.869578   \n",
       "3  3    0.179\n",
       "Name: Central Point Dominance, dtyp...         0.000000   \n",
       "\n",
       "                                         Modularidad  Colaboratividad 1  \\\n",
       "0                                           0.916538           0.343967   \n",
       "1                                           0.931992           0.445472   \n",
       "2                                           0.924265           0.394720   \n",
       "3  3    0.611\n",
       "Name: Modularidad con pesos (1.0), ...           0.000000   \n",
       "\n",
       "   Colaboratividad 2  \n",
       "0           0.507654  \n",
       "1           0.567307  \n",
       "2           0.537480  \n",
       "3           0.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----------------------\n",
    "# Monte Carlo\n",
    "#----------------------\n",
    "\n",
    "\n",
    "\n",
    "def monte_carlo_for_city(infos, city, prob_out, prob_new, num_trials, infocolab1, infocolab2):\n",
    "    data = {'Name':[],\n",
    "            'Degree':[],\n",
    "            'Eccentricity':[],\n",
    "            'clustering':[],\n",
    "            'Diámetro':[],\n",
    "            'Radio':[],\n",
    "            'Camino más corto promedio':[],\n",
    "            'Transitividad':[],\n",
    "            'Eficiencia Global':[],\n",
    "            'Small Worldness':[],\n",
    "            'Rich Club Coefficient':[],\n",
    "            'Core Ratio':[],\n",
    "            'Central Point Dominance':[],\n",
    "            'Spectral radius':[],\n",
    "            'Modularidad':[],\n",
    "            'Colaboratividad 1':[],\n",
    "            'Colaboratividad 2':[]} \n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        G = random_graph_3(infos,city,prob_out, prob_new)\n",
    "        U = nx.to_undirected(G)\n",
    "        \n",
    "        data['Name'].append('G'+str(i))\n",
    "        \n",
    "        data['Degree'].append( np.mean([G.degree(x) for x in G.nodes()]) )\n",
    "        data['Eccentricity'].append( np.mean([nx.eccentricity(U,x) for x in U.nodes()]) )\n",
    "        #data['clustering'].append( np.mean([nx.clustering(U,x) for x in U.nodes()]) )\n",
    "\n",
    "        #data['Diámetro'].append(  nx.diameter(U)  )\n",
    "        #data['Radio'].append(  nx.radius(U)  )\n",
    "\n",
    "        #data['Camino más corto promedio'].append( nx.average_shortest_path_length(U) )\n",
    "        data['Transitividad'].append( nx.transitivity(U) )\n",
    "        data['Eficiencia Global'].append( nx.global_efficiency(U) )\n",
    "        data['Small Worldness'].append( nx.algorithms.smallworld.sigma(U,niter=1,nrand=2) )\n",
    "        data['Rich Club Coefficient'].append( max_rich_club(U) )\n",
    "        data['Core Ratio'].append( core_ratio(U) )\n",
    "        data['Central Point Dominance'].append(central_point_dominance(U))\n",
    "        data['Spectral radius'].append( spectral_radius(U) )\n",
    "        data['Modularidad'].append(nx.algorithms.community.quality.performance(U,nx.algorithms.community.modularity_max.greedy_modularity_communities(U)))\n",
    "        #data['Colaboratividad 1'].append(colaborativity(G, infocolab1[0], infocolab1[1], infocolab1[2], infocolab1[3]))\n",
    "        #data['Colaboratividad 2'].append(colaborativity(G, infocolab2[0], infocolab2[1], infocolab2[2], infocolab2[3]))\n",
    "        data['Colaboratividad 1'].append(colaborativity_from_dataframe(G, i, data, infocolab1[0], infocolab1[1], infocolab1[2], infocolab1[3]))\n",
    "        data['Colaboratividad 2'].append(colaborativity_from_dataframe(G, i, data, infocolab2[0], infocolab2[1], infocolab2[2], infocolab2[3]))\n",
    "        print(i)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #mean of all data\n",
    "    G = random_graph_3(infos,city,prob_out, prob_new)\n",
    "    U = nx.to_undirected(G)\n",
    "    data['Name'].append('Mean')\n",
    "    data['Degree'].append( np.mean(data['Degree']) )\n",
    "    data['Eccentricity'].append( np.mean(data['Eccentricity'] ))\n",
    "    #data['clustering'].append( np.mean(data['clustering']) )\n",
    "    #data['Diámetro'].append(  np.mean(data['Diámetro'])  )\n",
    "    #data['Radio'].append(  np.mean(data['Radio'])  )\n",
    "    #data['Camino más corto promedio'].append( np.mean(data['Camino más corto promedio']) )\n",
    "    data['Transitividad'].append( np.mean(data['Transitividad']) )\n",
    "    data['Eficiencia Global'].append( np.mean(data['Eficiencia Global']) )\n",
    "    data['Small Worldness'].append( np.mean(data['Small Worldness']) )\n",
    "    data['Rich Club Coefficient'].append( np.mean(data['Rich Club Coefficient']) )\n",
    "    data['Core Ratio'].append( np.mean(data['Core Ratio']) )\n",
    "    data['Central Point Dominance'].append(np.mean(data['Central Point Dominance']))\n",
    "    data['Spectral radius'].append( np.mean(data['Spectral radius']) )\n",
    "    data['Modularidad'].append( np.mean(data['Modularidad']) )\n",
    "    data['Colaboratividad 1'].append( np.mean(data['Colaboratividad 1']) )\n",
    "    data['Colaboratividad 2'].append( np.mean(data['Colaboratividad 2']) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #real data\n",
    "    tidydata = pd.read_csv('Tidy_DataFrame.csv')\n",
    "    citydata = tidydata.loc[tidydata['Ciudad'] == city]\n",
    "    data['Name'].append(city+' real')\n",
    "    data['Degree'].append( citydata['Degree'] )\n",
    "    data['Eccentricity'].append( citydata['Eccentricidad'] )\n",
    "    #data['clustering'].append( np.mean([nx.clustering(U,x) for x in U.nodes()]) )\n",
    "    #data['Diámetro'].append(  nx.diameter(U)  )\n",
    "    #data['Radio'].append(  nx.radius(U)  )\n",
    "    #data['Camino más corto promedio'].append( nx.average_shortest_path_length(U) )\n",
    "    data['Transitividad'].append( citydata['Transitividad'] )\n",
    "    data['Eficiencia Global'].append( citydata['Eficiencia Global'] )\n",
    "    data['Small Worldness'].append( citydata['Small Worldness'] )\n",
    "    data['Rich Club Coefficient'].append( citydata['Rich Club Coefficient'] )\n",
    "    data['Core Ratio'].append( citydata['Core Ratio'] )\n",
    "    data['Central Point Dominance'].append( citydata['Central Point Dominance'] )\n",
    "    data['Spectral radius'].append( 0 )\n",
    "    data['Modularidad'].append(citydata['Modularidad con pesos (1.0)'])\n",
    "    data['Colaboratividad 1'].append(0)\n",
    "    data['Colaboratividad 2'].append(0)\n",
    "    \n",
    "    #data['Colaboratividad 1'].append(colaborativity_from_dataframe(G, -1, data, infocolab1[0], infocolab1[1], infocolab1[2], infocolab1[3]))\n",
    "    #data['Colaboratividad 2'].append(colaborativity_from_dataframe(G, -1, data, infocolab2[0], infocolab2[1], infocolab2[2], infocolab2[3]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #'avg strength', 'weight', 'Weighted Degree'\n",
    "    df = pd.DataFrame(data, columns = ['Name','Degree', 'Eccentricity', \n",
    "                                       #'clustering', 'Diámetro', 'Radio', 'Camino más corto promedio', \n",
    "                                       'Transitividad', 'Eficiencia Global','Small Worldness',\n",
    "                                       'Rich Club Coefficient', 'Core Ratio', 'Central Point Dominance', \n",
    "                                       'Spectral radius', 'Modularidad', 'Colaboratividad 1', 'Colaboratividad 2'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#G = random_graph_3(cities_info,'GDL',0.8, 0.6)\n",
    "\n",
    "#each collaborativity formula data consists in the contributors to \n",
    "# - communication\n",
    "# - preparation\n",
    "# - resilience\n",
    "\n",
    "infocolab1=[{'Eficiencia Global'}, {'Rich Club Coefficient'}, {'Transitividad'}, 'arithmetic']\n",
    "infocolab2=[{'Eficiencia Global'}, {'Small Worldness', 'Rich Club Coefficient'}, {'Modularidad', 'Transitividad'}, 'quadratic']\n",
    "\n",
    "#infocolab1=[['Eficiencia Global'], ['Rich Club Coefficient'], ['Transitividad'], 'arithmetic']\n",
    "#infocolab2=[['Eficiencia Global'], ['Small Worldness', 'Rich Club Coefficient'], ['Modularidad', 'Transitividad'], 'quadratic']\n",
    "\n",
    "\n",
    "\n",
    "monte_carlo_for_city(cities_info, 'Montevideo', 0.8, 0.6, 2, infocolab1, infocolab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic(L):\n",
    "    n = len(L)\n",
    "    sum_reciprocals = sum([1/x for x in L])\n",
    "    return n/sum_reciprocals\n",
    "\n",
    "dictio = {'h':harmonic}\n",
    "\n",
    "dictio['h']([1,2,23,4])"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
