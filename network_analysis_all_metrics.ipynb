{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iGED : Global Systems Dynamics Initiative\n",
    "\n",
    "El objetivo principal de este documento es analizar las métricas globales en las siguientes redes capitales\n",
    "\n",
    "  *  Ciudad Autónoma de Buenos Aires (CABA)\n",
    "  *  Ciudad de México (CDMX)\n",
    "  *  Santiago de Chile (SCL)\n",
    "  *  Montevideo (MTV)\n",
    "  *  Madrid (MAD)\n",
    "  *  Sao Paulo (SAO)\n",
    "\n",
    "y obtener un tidy DataFrame, para continuar analizando los datos obtenidos, por ejemplo obteniendo correlaciones entre parejas de métricas.\n",
    "\n",
    "Respecto al notebook anterior, utilizamos la documentación de NetworkX: https://www.nas.ewi.tudelft.nl/people/Piet/papers/TUDreport20111111_MetricList.pdf\n",
    "\n",
    "así como el siguiente recurso: https://www.nas.ewi.tudelft.nl/people/Piet/papers/TUDreport20111111_MetricList.pdf\n",
    "\n",
    "para saber con cuáles métricas globales seguir estudiando nuestros ecosistemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------\n",
    "# Importar paquetes a utilizar\n",
    "#-------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import networkx as nx\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "#-------------------------------------------------------\n",
    "# Archivo CSV describiendo los nodos de cada red\n",
    "#-------------------------------------------------------\n",
    "ags_nd=pd.read_csv('Gephi_stats/Gephi AGS Stats.csv')             \n",
    "caba_nd=pd.read_csv('Gephi_stats/Gephi CABA Stats.csv')           #capital\n",
    "cdmx_nd=pd.read_csv('Gephi_stats/Gephi CDMX Stats.csv')           #capital\n",
    "gdl_nd=pd.read_csv('Gephi_stats/Gephi GDL Stats.csv') \n",
    "hgo_nd=pd.read_csv('Gephi_stats/Gephi Hidalgo Stats.csv')\n",
    "mad_nd=pd.read_csv('Gephi_stats/Gephi Madrid Stats.csv')          #capital\n",
    "mtv_nd=pd.read_csv('Gephi_stats/Gephi Montevideo Stats.csv')      #capital\n",
    "oax_nd=pd.read_csv('Gephi_stats/Gephi Oaxaca Stats.csv')\n",
    "sao_nd=pd.read_csv('Gephi_stats/Gephi Sao Paulo Stats.csv')       #capital\n",
    "scl_nd=pd.read_csv('Gephi_stats/Gephi SCL Stats.csv')             #capital\n",
    "\n",
    "\n",
    "#-------------------------------------------------------\n",
    "# Archivo CSV describiendo las aristas de cada red\n",
    "#-------------------------------------------------------\n",
    "ags_ed=pd.read_csv('Gephi_edges/Gephi AGS Edges.csv')\n",
    "caba_ed=pd.read_csv('Gephi_edges/Gephi CABA Edges.csv')           #capital\n",
    "cdmx_ed=pd.read_csv('Gephi_edges/Gephi CDMX Edges.csv')           #capital\n",
    "gdl_ed=pd.read_csv('Gephi_edges/Gephi GDL Edges.csv')\n",
    "hgo_ed=pd.read_csv('Gephi_edges/Gephi Hidalgo Edges.csv')\n",
    "mad_ed=pd.read_csv('Gephi_edges/Gephi Madrid Edges.csv')          #capital\n",
    "mtv_ed=pd.read_csv('Gephi_edges/Gephi Montevideo Edges.csv')      #capital\n",
    "oax_ed=pd.read_csv('Gephi_edges/Gephi Oaxaca Edges.csv')\n",
    "sao_ed=pd.read_csv('Gephi_edges/Gephi Sao Paulo Edges.csv')       #capital\n",
    "scl_ed=pd.read_csv('Gephi_edges/Gephi SCL Edges.csv')             #capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def armar_grafo(nodes,edges,rol_str,weight_str):\n",
    "    '''\n",
    "    Función con la cual, a partir de una lista de nodos y conexiones, forma un grafo con NetworkX\n",
    "    \n",
    "    In:\n",
    "    - nodes       lista de nodos\n",
    "    - edges       lista de aristas\n",
    "    - rol_str     un nombre para el parámetro que describe el rol de un actor\n",
    "    - weight_str  un nombre para el parámetro que describe el peso de las aristas\n",
    "    \n",
    "    Out\n",
    "    Un DiGrafo NetworkX llamado G.\n",
    "    '''\n",
    "    \n",
    "    #crea un grafo dirigido a partir de la lista edges\n",
    "    G=nx.from_pandas_edgelist(edges,'Source','Target',edge_attr=[\"Weight\"],create_using=nx.DiGraph())\n",
    "    #G=nx.from_pandas_edgelist(edges,'Source','Target',edge_attr=[\"Weight\"],create_using=nx.MultiDiGraph())\n",
    "\n",
    "    #rol es un diccionario que manda cada id de un nodo a el atributo correspondiente a rol\n",
    "    rol = {nid: nodes[nodes['Id']==nid][rol_str].values[0] for nid in nodes['Id']}\n",
    "    nx.set_node_attributes(G,rol,'rol')\n",
    "    \n",
    "    #weight es un diccionario que manda cada id de un nodo a el atributo correspondiente al peso de nodo\n",
    "    weight = {nid: nodes[nodes['Id']==nid][weight_str].values[0] for nid in nodes['Id']}\n",
    "    nx.set_node_attributes(G,weight,'weight')\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------\n",
    "#Armar grafos a partir de cada uno de los CSV que descargamos\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "ags_G=armar_grafo(ags_nd,ags_ed,'role','weight')\n",
    "caba_G=armar_grafo(caba_nd,caba_ed,'type','weight')\n",
    "cdmx_G=armar_grafo(cdmx_nd,cdmx_ed,'rol estimado','weight')\n",
    "gdl_G=armar_grafo(gdl_nd,gdl_ed,'type','weight')\n",
    "hgo_G=armar_grafo(hgo_nd,hgo_ed,'type','weight')\n",
    "mad_G=armar_grafo(mad_nd,mad_ed,'rol estimado','weight')\n",
    "mtv_G=armar_grafo(mtv_nd,mtv_ed,'rol estimado','node size')\n",
    "oax_G=armar_grafo(oax_nd,oax_ed,'rol','weight')\n",
    "sao_G=armar_grafo(sao_nd,sao_ed,'rol estimado','weight')\n",
    "scl_G=armar_grafo(scl_nd,scl_ed,'type','weight')\n",
    "\n",
    "\n",
    "#ahora vamos a salvar este trabajo y escribir estos grafos\n",
    "nx.write_graphml(ags_G,'GraphMLs/AGS original graph.graphml')\n",
    "nx.write_graphml(caba_G,'GraphMLs/CABA original graph.graphml')\n",
    "nx.write_graphml(cdmx_G,'GraphMLs/CDMX original graph.graphml')\n",
    "nx.write_graphml(gdl_G,'GraphMLs/GDL original graph.graphml')\n",
    "nx.write_graphml(hgo_G,'GraphMLs/Pachuca original graph.graphml')\n",
    "nx.write_graphml(mad_G,'GraphMLs/Madrid original graph.graphml')\n",
    "nx.write_graphml(mtv_G,'GraphMLs/Montevideo original graph.graphml')\n",
    "nx.write_graphml(oax_G,'GraphMLs/Oaxaca original graph.graphml')\n",
    "nx.write_graphml(sao_G,'GraphMLs/Sao Paulo original graph.graphml')\n",
    "nx.write_graphml(scl_G,'GraphMLs/Santiago original graph.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de artibuto Rol para la ciudad de CABA\n",
      "\n",
      "[[0.01508621 0.0387931  0.00862069 0.01724138 0.04741379 0.        ]\n",
      " [0.05603448 0.31896552 0.01077586 0.06896552 0.12715517 0.01939655]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.00431034 0.05603448 0.00431034 0.03017241 0.0237069  0.01077586]\n",
      " [0.01724138 0.05603448 0.         0.01508621 0.03232759 0.        ]\n",
      " [0.00215517 0.01508621 0.         0.         0.00431034 0.        ]]\n",
      "\n",
      "\n",
      "Matriz de artibuto Rol para la ciudad de CDMX\n",
      "\n",
      "[[0.00398406 0.02390438 0.00199203 0.00199203 0.01195219 0.        ]\n",
      " [0.03784861 0.51394422 0.02390438 0.06772908 0.10956175 0.02788845]\n",
      " [0.00199203 0.02191235 0.00398406 0.         0.         0.        ]\n",
      " [0.00199203 0.02988048 0.         0.00199203 0.00398406 0.00199203]\n",
      " [0.00199203 0.01992032 0.         0.00199203 0.00796813 0.00398406]\n",
      " [0.         0.05179283 0.0059761  0.0059761  0.00398406 0.00398406]]\n",
      "\n",
      "\n",
      "Matriz de artibuto Rol para la ciudad de Santiago de Chile\n",
      "\n",
      "[[0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.37109375 0.0078125  0.05859375 0.1015625  0.01171875]\n",
      " [0.         0.01171875 0.         0.         0.00390625 0.        ]\n",
      " [0.         0.1015625  0.00390625 0.02734375 0.046875   0.00390625]\n",
      " [0.         0.11328125 0.0234375  0.00390625 0.046875   0.00390625]\n",
      " [0.         0.03125    0.         0.01171875 0.01171875 0.00390625]]\n",
      "\n",
      "\n",
      "Matriz de artibuto Rol para la ciudad de Montevideo\n",
      "\n",
      "[[0.02529762 0.05505952 0.         0.01339286 0.03125    0.        ]\n",
      " [0.07291667 0.22172619 0.02529762 0.07738095 0.14136905 0.00297619]\n",
      " [0.         0.0014881  0.         0.00744048 0.0014881  0.        ]\n",
      " [0.01041667 0.03422619 0.01041667 0.02380952 0.02827381 0.        ]\n",
      " [0.0297619  0.07440476 0.00446429 0.03720238 0.05208333 0.        ]\n",
      " [0.         0.00744048 0.         0.         0.0014881  0.00892857]]\n",
      "\n",
      "\n",
      "Matriz de artibuto Rol para la ciudad de Madrid\n",
      "\n",
      "[[0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.42378049 0.02743902 0.06402439 0.11280488 0.01829268]\n",
      " [0.         0.02439024 0.         0.         0.00914634 0.        ]\n",
      " [0.         0.03963415 0.         0.01829268 0.02134146 0.        ]\n",
      " [0.         0.07012195 0.00609756 0.04268293 0.07621951 0.        ]\n",
      " [0.         0.0304878  0.00609756 0.00304878 0.00609756 0.        ]]\n",
      "\n",
      "\n",
      "Matriz de artibuto Rol para la ciudad de Sao Paulo\n",
      "\n",
      "[[0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.56457565 0.0295203  0.08487085 0.11439114 0.01107011]\n",
      " [0.         0.00369004 0.00738007 0.00369004 0.         0.        ]\n",
      " [0.         0.06273063 0.         0.00369004 0.00738007 0.00369004]\n",
      " [0.         0.06273063 0.00369004 0.01476015 0.01845018 0.00369004]\n",
      " [0.         0.         0.         0.         0.         0.        ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------\n",
    "# Attribute Mixing Matrices - Original graphs\n",
    "#-------------------------------------------------\n",
    "#       Obtenemos una matriz cuya entrada (i,j) es la fracción de aristas \n",
    "#       que van de un eje con rol i a un eje con rol j, en la red original\n",
    "\n",
    "\n",
    "#cada rol lo asignamos a un índice del 1 al 5\n",
    "rol_map_esp={'Generador de conocimiento':0,'Habilitador':1,'Promotor':2,\n",
    "             'Vinculador':3,'Articulador':4,'Comunidad':5}\n",
    "\n",
    "rol_map_ing={'Knowledge Generator':0,'Enabler':1,\n",
    "             'Promoter':2,'Linker':3,'Articulator':4,'Community':5}\n",
    "\n",
    "capitals = {'CABA': caba_G, 'CDMX':cdmx_G, 'Santiago de Chile': scl_G, \n",
    "            'Montevideo': mtv_G, 'Madrid': mad_G, 'Sao Paulo': sao_G}\n",
    "\n",
    "#aquí vamos a almacenar las matrices\n",
    "attr_mix_matrices = capitals \n",
    "\n",
    "#conseguimos cada una de las attribute mixing matrices\n",
    "for capital_str in capitals.keys():\n",
    "    if capital_str=='Montevideo':\n",
    "        print('Matriz de artibuto Rol para la ciudad de '+capital_str)\n",
    "        print('')\n",
    "        M=nx.attribute_mixing_matrix(capitals[capital_str],'rol',mapping=rol_map_ing)\n",
    "        print(M)\n",
    "        print('')\n",
    "        print('')\n",
    "    else:\n",
    "        print('Matriz de artibuto Rol para la ciudad de '+capital_str)\n",
    "        print('')\n",
    "        M=nx.attribute_mixing_matrix(capitals[capital_str],'rol',mapping=rol_map_esp)\n",
    "        print(M)\n",
    "        print('')\n",
    "        print('')\n",
    "    attr_mix_matrices[capital_str] = M\n",
    "\n",
    "            \n",
    "# Creamos la instancia de una figura, con subplots\n",
    "fig = plt.figure(figsize = (20,20)) # ancho x alto\n",
    "\n",
    "ax1 = fig.add_subplot(3, 3, 1) # row, column, position\n",
    "ax1.set_title('Matriz de artibuto Rol para la ciudad de CABA')\n",
    "\n",
    "ax2 = fig.add_subplot(3, 3, 2)\n",
    "ax2.set_title('Matriz de artibuto Rol para la ciudad de CDMX')\n",
    "\n",
    "ax3 = fig.add_subplot(3, 3, 3)\n",
    "ax3.set_title('Matriz de artibuto Rol para la ciudad de Santiago de Chile')\n",
    "\n",
    "ax4 = fig.add_subplot(3, 3, 4)\n",
    "ax4.set_title('Matriz de artibuto Rol para la ciudad de Montevideo')\n",
    "\n",
    "ax5 = fig.add_subplot(3, 3, 5)\n",
    "ax5.set_title('Matriz de artibuto Rol para la ciudad de Madrid')\n",
    "\n",
    "ax6 = fig.add_subplot(3, 3, 6)\n",
    "ax6.set_title('Matriz de artibuto Rol para la ciudad de Sao Paulo')\n",
    "\n",
    "\n",
    "# We use ax parameter to tell seaborn which subplot to use for this plot\n",
    "heat_caba = sns.heatmap(data=attr_mix_matrices['CABA'], ax=ax1, square=True, cbar_kws={'shrink': .3}, annot=True, annot_kws={'fontsize': 12}, vmin=0.0, vmax=0.6)\n",
    "\n",
    "heat_cdmx = sns.heatmap(data=attr_mix_matrices['CDMX'], ax=ax2, square=True, cbar_kws={'shrink': .3}, annot=True, annot_kws={'fontsize': 12}, vmin=0.0, vmax=0.6)\n",
    "heat_scl = sns.heatmap(data=attr_mix_matrices['Santiago de Chile'], ax=ax3, square=True, cbar_kws={'shrink': .3}, annot=True, annot_kws={'fontsize': 12}, vmin=0.0, vmax=0.6)\n",
    "heat_mtv = sns.heatmap(data=attr_mix_matrices['Montevideo'], ax=ax4, square=True, cbar_kws={'shrink': .3}, annot=True, annot_kws={'fontsize': 12}, vmin=0.0, vmax=0.6)\n",
    "heat_mad = sns.heatmap(data=attr_mix_matrices['Madrid'], ax=ax5, square=True, cbar_kws={'shrink': .3}, annot=True, annot_kws={'fontsize': 12}, vmin=0.0, vmax=0.6)      \n",
    "heat_sao = sns.heatmap(data=attr_mix_matrices['Sao Paulo'], ax=ax6, square=True, cbar_kws={'shrink': .3}, annot=True, annot_kws={'fontsize': 12}, vmin=0.0, vmax=0.6)      \n",
    "\n",
    "\n",
    "fig.savefig('all_heatmaps.png', dpi=400)\n",
    "\n",
    "#fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Subgrafos Nucleares \n",
    "#----------------------\n",
    "#    Obtenemos los -core- nodes (nodos núcleo) de cada una de las redes capitales, \n",
    "#    donde el grado total de un nodo núcleo es al menos 3\n",
    "\n",
    "caba_core=nx.k_core(caba_G,k=3)\n",
    "cdmx_core=nx.k_core(cdmx_G,k=3)\n",
    "scl_core=nx.k_core(scl_G,k=3)\n",
    "mad_core=nx.k_core(mad_G,k=3)\n",
    "mtv_core=nx.k_core(mtv_G,k=3)\n",
    "sao_core=nx.k_core(sao_G,k=3)\n",
    "\n",
    "#----------------------\n",
    "# GraphMLs Nucleares\n",
    "#----------------------\n",
    "#    Ahora, convertimos cada uno de los subgrafos nucleares que obtuvimos\n",
    "#    en un archivo .graphml\n",
    "\n",
    "nx.write_graphml(caba_core,'Gephi_core/CABA core graph.graphml')\n",
    "nx.write_graphml(cdmx_core,'Gephi_core/CDMX core graph.graphml')\n",
    "nx.write_graphml(scl_core,'Gephi_core/Scl core graph.graphml')\n",
    "nx.write_graphml(mad_core,'Gephi_core/Mad core graph.graphml')\n",
    "nx.write_graphml(mtv_core,'Gephi_core/Mtv core graph.graphml')\n",
    "nx.write_graphml(sao_core,'Gephi_core/Sao core graph.graphml')\n",
    "\n",
    "#----------------------\n",
    "# Subgrafos Corteza \n",
    "#----------------------\n",
    "#    Obtenemos los -crust- nodes (nodos corteza) de cada una de las redes capitales, \n",
    "#    donde el grado total de un nodo corteza es menor a 3\n",
    "\n",
    "caba_crust=nx.k_crust(caba_G,k=3)\n",
    "cdmx_crust=nx.k_crust(cdmx_G,k=3)\n",
    "scl_crust=nx.k_crust(scl_G,k=3)\n",
    "mad_crust=nx.k_crust(mad_G,k=3)\n",
    "mtv_crust=nx.k_crust(mtv_G,k=3)\n",
    "sao_crust=nx.k_crust(sao_G,k=3)\n",
    "\n",
    "#----------------------\n",
    "# GraphMLs Corteza  \n",
    "#----------------------\n",
    "#    Ahora, convertimos cada uno de los subgrafos corteza que obtuvimos\n",
    "#    en un archivo .graphml\n",
    "\n",
    "nx.write_graphml(caba_crust,'Gephi_crust/CABA crust graph.graphml')\n",
    "nx.write_graphml(cdmx_crust,'Gephi_crust/CDMX crust graph.graphml')\n",
    "nx.write_graphml(scl_crust,'Gephi_crust/Scl crust graph.graphml')\n",
    "nx.write_graphml(mad_crust,'Gephi_crust/Mad crust graph.graphml')\n",
    "nx.write_graphml(mtv_crust,'Gephi_crust/Mtv crust graph.graphml')\n",
    "nx.write_graphml(sao_crust,'Gephi_crust/Sao crust graph.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "#  Attribute Mixing Matrices - Core graphs\n",
    "#------------------------------------------------\n",
    "#     Para cada uno de los grafos corteza que conseguimos, \n",
    "#     Obtenemos una matriz cuya entrada (i,j) es la fracción \n",
    "#     de aristas que van de un eje con rol i a un eje con rol j\n",
    "\n",
    "\n",
    "rol_map_esp={'Generador de conocimiento':0,'Habilitador':1,'Promotor':2,\n",
    "             'Vinculador':3,'Articulador':4,'Comunidad':5}\n",
    "\n",
    "rol_map_ing={'Knowledge Generator':0,'Enabler':1,'Promoter':2,\n",
    "             'Linker':3,'Articulator':4,'Community':5}\n",
    "\n",
    "capitals_cores={'CABA': caba_core, 'CDMX':cdmx_core, 'Santiago de Chile': scl_core, \n",
    "                'Montevideo': mtv_core, 'Madrid': mad_core, 'Sao Paulo': sao_core}\n",
    "attr_mix_matrices = capitals_cores \n",
    "        \n",
    "\n",
    "\n",
    "for capital_str in capitals.keys():\n",
    "    if capital_str=='Montevideo':\n",
    "        print('Matriz de artibuto Rol para el núcleo (k=3) de '+capital_str)\n",
    "        print('')\n",
    "        M=nx.attribute_mixing_matrix(capitals_cores[capital_str],'rol',mapping=rol_map_ing)\n",
    "        print(M)\n",
    "        print('')\n",
    "        print('')\n",
    "    else:\n",
    "        print('Matriz de artibuto Rol para el núcleo (k=3) de '+capital_str)\n",
    "        print('')\n",
    "        M=nx.attribute_mixing_matrix(capitals_cores[capital_str],'rol',mapping=rol_map_esp)\n",
    "        print(M)\n",
    "        print('')\n",
    "        print('')\n",
    "    attr_mix_matrices[capital_str] = M\n",
    "\n",
    "        \n",
    "        \n",
    "# Creamos la instancia de una figura, con subplots\n",
    "fig = plt.figure(figsize = (20,20)) # width x height\n",
    "ax1 = fig.add_subplot(3, 3, 1) # row, column, position\n",
    "ax1.set_title('Matriz de artibuto Rol para el núcleo (k=3) de CABA')\n",
    "\n",
    "ax2 = fig.add_subplot(3, 3, 2)\n",
    "ax2.set_title('Matriz de artibuto Rol para el núcleo (k=3) de CDMX')\n",
    "\n",
    "ax3 = fig.add_subplot(3, 3, 3)\n",
    "ax3.set_title('Matriz de artibuto Rol para el núcleo (k=3) de Santiago de Chile')\n",
    "\n",
    "ax4 = fig.add_subplot(3, 3, 4)\n",
    "ax4.set_title('Matriz de artibuto Rol para el núcleo (k=3) de Montevideo')\n",
    "\n",
    "ax5 = fig.add_subplot(3, 3, 5)\n",
    "ax5.set_title('Matriz de artibuto Rol para el núcleo (k=3) de Madrid')\n",
    "\n",
    "ax6 = fig.add_subplot(3, 3, 6)\n",
    "ax6.set_title('Matriz de artibuto Rol para el núcleo (k=3) de Sao Paulo')\n",
    "\n",
    "\n",
    "# We use ax parameter to tell seaborn which subplot to use for this plot\n",
    "sns.heatmap(data=attr_mix_matrices['CABA'], ax=ax1, square=True, cbar_kws={'shrink': .3}, annot=True, annot_kws={'fontsize': 12}, vmin=0.0, vmax=0.6)\n",
    "sns.heatmap(data=attr_mix_matrices['CDMX'], ax=ax2, square=True, cbar_kws={'shrink': .3}, annot=True, annot_kws={'fontsize': 12}, vmin=0.0, vmax=0.6)\n",
    "sns.heatmap(data=attr_mix_matrices['Santiago de Chile'], ax=ax3, square=True, cbar_kws={'shrink': .3}, annot=True, annot_kws={'fontsize': 12}, vmin=0.0, vmax=0.6)\n",
    "sns.heatmap(data=attr_mix_matrices['Montevideo'], ax=ax4, square=True, cbar_kws={'shrink': .3}, annot=True, annot_kws={'fontsize': 12}, vmin=0.0, vmax=0.6)\n",
    "sns.heatmap(data=attr_mix_matrices['Madrid'], ax=ax5, square=True, cbar_kws={'shrink': .3}, annot=True, annot_kws={'fontsize': 12}, vmin=0.0, vmax=0.6)      \n",
    "sns.heatmap(data=attr_mix_matrices['Sao Paulo'], ax=ax6, square=True, cbar_kws={'shrink': .3}, annot=True, annot_kws={'fontsize': 12}, vmin=0.0, vmax=0.6)      \n",
    "\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# Medidas Globales\n",
    "#----------------------------\n",
    "#     Ahora obtenemos, para cada una de las capitales, una serie \n",
    "#     pandas.core.series.Series, utilizando la función mean(), \n",
    "#     con la que obtenemos los promedios de cada columna. \n",
    "#     Los más relevantes son:\n",
    " \n",
    "#           - avg strength                    fuerza promedio de sus interacciones (1-5)\n",
    "#           - weight                          promedio del peso de los nodos\n",
    "#           - Degree                          promedio de grado, hacia o desde el nodo\n",
    "#           - Weighted Degree                 promedio de grado, hacia o desde el nodo de acuerdo a intensidades\n",
    "\n",
    "#           - Eccentricity                   promedio de centralidades\n",
    "#           - closnesscentrality              \n",
    "#           - harmonicclosnesscentrality      \n",
    "#           - betweenesscentrality  \n",
    "#           - clustering                     promedio de coeficiente de aglomeración\n",
    "\n",
    "        \n",
    "#           - Authority                       promedio de valor autoridad de los nodos (HITS)\n",
    "#           - Authority                       promedio de valor hub de los nodos (HITS)\n",
    "\n",
    "#           - triangles                       número de triágulos\n",
    "#           - eigencentrality                 promedio de centralidades eigenvectores\n",
    "\n",
    "capitals_stats={'CABA': caba_nd, 'CDMX':cdmx_nd, 'Santiago de Chile': scl_nd, \n",
    "                'Montevideo': mtv_nd, 'Madrid': mad_nd, 'Sao Paulo': sao_nd}\n",
    "\n",
    "\n",
    "averages={city: stats.mean() for city,stats in capitals_stats.items()}\n",
    "#averages['Sao Paulo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries={'Montevideo':'Uruguay', 'CABA':'Argentina', 'CDMX':'México',\n",
    "          'Madrid':'España', 'Sao Paulo': 'Brasil', 'Santiago de Chile': 'Chile'}\n",
    "\n",
    "\n",
    "list_concat=[]\n",
    "for city,avg in averages.items():\n",
    "    datafr=avg.copy().to_frame().T\n",
    "    \n",
    "    #borramos del set de columnas a aquellos atributos que no son significantes \n",
    "    datafr.drop(['timeset', 'componentnumber'], axis=1, inplace=True)\n",
    "    if 'type' in datafr.columns:\n",
    "        datafr.drop(['type'], axis=1, inplace=True)\n",
    "    \n",
    "    #añadimos datafr a la lista de dataframes que vamos a concatenar\n",
    "    list_concat.append(datafr)\n",
    "    \n",
    "    #añadimos el atributo que corresponde a el nombre de ciudad y país\n",
    "    datafr.insert(0, 'País', [countries[city]], True) \n",
    "    datafr.insert(0, 'Ciudad', [city], True) \n",
    "\n",
    "df_concat=pd.concat(list_concat, ignore_index=True)\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitar promedios que en la pagina no mencionan que describen una propiedad global del grafo\n",
    "\n",
    "df_concat=df_concat.drop('closnesscentrality',axis=1)\n",
    "df_concat=df_concat.drop('harmonicclosnesscentrality',axis=1)\n",
    "df_concat=df_concat.drop('modularity_class',axis=1)\n",
    "df_concat=df_concat.drop('triangles',axis=1)\n",
    "df_concat=df_concat.drop('eigencentrality',axis=1)\n",
    "df_concat=df_concat.drop('pageranks',axis=1)\n",
    "df_concat=df_concat.drop('ego',axis=1)\n",
    "df_concat=df_concat.drop('betweenesscentrality',axis=1)\n",
    "df_concat=df_concat.drop('Hub',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitar promedios que son redundantes, ya que al hacer el análisis presentaron correlación de 1\n",
    "\n",
    "df_concat=df_concat.drop('indegree',axis=1)\n",
    "df_concat=df_concat.drop('outdegree',axis=1)\n",
    "df_concat=df_concat.drop('weighted indegree',axis=1)\n",
    "df_concat=df_concat.drop('weighted outdegree',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['weight'][3]=df_concat['node size'][3]\n",
    "df_concat=df_concat.drop('node size',axis=1)\n",
    "df_concat=df_concat.drop('strongcompnum',axis=1)\n",
    "df_concat=df_concat.drop('Authority',axis=1)\n",
    "\n",
    "#una de las columnas que generaba una entrada NaN\n",
    "df_concat=df_concat.drop('mentions',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Global characteristics we may compute:\n",
    "\n",
    "*Diameter  \n",
    "*Radius\n",
    "**Average path length\n",
    "**Transitivity\n",
    "*Global Efficiency\n",
    "***Modularity\n",
    "*Assortativity Coefficient\n",
    "Small Worldness\n",
    "\n",
    "\n",
    "*   = computed already, not defined for direted graph\n",
    "**  = computed for undirected graph, also defined for directed graph\n",
    "*** = computed manually\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------\n",
    "# Small Worldness\n",
    "#------------------\n",
    "\n",
    "'''\n",
    "#networkx.algorithms.smallworld.random_reference\n",
    "print('----------------------------------')\n",
    "print('Small Worldness en Cores dirigidos')\n",
    "print('----------------------------------')\n",
    "\n",
    "for city, graph in capitals.items():\n",
    "    try:\n",
    "        print(city+str(': ')+str(nx.algorithms.smallworld.sigma(graph,niter=1,nrand=2)))\n",
    "        print('')\n",
    "    except:\n",
    "        print(city+str(': ')+str(float('inf')))\n",
    "        print('')\n",
    "\n",
    "print('----------------------------------')\n",
    "print('Small Worldness en Cores no dirigidos')\n",
    "print('----------------------------------')\n",
    "\n",
    "for city, graph in capitals.items():\n",
    "    try:\n",
    "        print(city+str(': ')+str(nx.algorithms.smallworld.sigma(graph.to_undirected(),niter=1,nrand=2)))\n",
    "        print('')\n",
    "    except:\n",
    "        print(city+str(': ')+str(float('inf')))\n",
    "        print('') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PRINT STATEMENT:\n",
    "\n",
    "----------------------------------\n",
    "Small Worldness en Cores dirigidos\n",
    "----------------------------------\n",
    "CABA: inf\n",
    "\n",
    "CDMX: inf\n",
    "\n",
    "Santiago de Chile: inf\n",
    "\n",
    "Montevideo: inf\n",
    "\n",
    "Madrid: inf\n",
    "\n",
    "Sao Paulo: inf\n",
    "\n",
    "----------------------------------\n",
    "Small Worldness en Cores no dirigidos\n",
    "----------------------------------\n",
    "CABA: 0.9608066521709907\n",
    "\n",
    "CDMX: 0.6771493264436462\n",
    "\n",
    "Santiago de Chile: 0.906813593858747\n",
    "\n",
    "Montevideo: 1.2745185062977642\n",
    "\n",
    "Madrid: 1.1410329702664386\n",
    "\n",
    "Sao Paulo: 1.211793728337516\n",
    "\n",
    "'''\n",
    "\n",
    "#    Por motivos de tiempo y de consistencia de nuestros datos \n",
    "#    (esta medida se computa a partir de una red al azar, entonces hay variabilidad),\n",
    "#    decidimos tomar una medida de Small worldness, \n",
    "#    registrarlo en una tabla y luego hacer el input manualmente. \n",
    "\n",
    "small_worldness = [0.9608066521709907, \n",
    "                  0.6771493264436462,\n",
    "                  0.906813593858747,\n",
    "                  1.2745185062977642,\n",
    "                  1.1410329702664386,\n",
    "                  1.211793728337516]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------\n",
    "#  Modularidades\n",
    "#-----------------\n",
    "#     Estas medidas fueron tomadas no por medio de este programa, sino manualmente desde el programa Gephi\n",
    "#     Metodología:\n",
    "#        Tomamos tres medidas en cada red, con cada una de las resoluciones 0.8, 1.0, 1.2, con o sin ejes\n",
    "#\n",
    "#        Network       (CABA, CDMX, MAD, MTV SAO, SCL)\n",
    "#        Resolution    (0.8, 1.0, 1.2)  \n",
    "#        Edge weights  (Y/N)\n",
    "#        \n",
    "#        Y luego de ello tomamos la mediana de las tres medidas de resolución, a modo de tomar en cuenta variabilidad\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "df_concat['Modularidad con pesos (0.8)'] = [0.402, 0.484, 0.530, 0.472, 0.611, 0.686]\n",
    "df_concat['Modularidad con pesos (1.0)'] = [0.524, 0.628, 0.530, 0.611, 0.610, 0.682]\n",
    "df_concat['Modularidad con pesos (1.2)'] = [0.654, 0.776, 0.524, 0.756, 0.612, 0.673]\n",
    "\n",
    "\n",
    "df_concat['Modularidad sin pesos (0.8)'] = [0.497, 0.602, 0.496, 0.353, 0.568, 0.673]\n",
    "df_concat['Modularidad sin pesos (1.0)'] = [0.493, 0.604, 0.500, 0.348, 0.572, 0.664]\n",
    "df_concat['Modularidad sin pesos (1.2)'] = [0.499, 0.601, 0.505, 0.337, 0.563, 0.661]\n",
    "\n",
    "df_concat\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# Central point of Dominance\n",
    "#--------------------------------\n",
    "\n",
    "\n",
    "def central_point_dominance(G):\n",
    "    betwennesses = nx.betweenness_centrality(G)\n",
    "    b_max = max(betwennesses.values())\n",
    "    N = len(betwennesses.keys())\n",
    "    count = 0\n",
    "    for i, b_i in betwennesses.items():\n",
    "        count += ( b_max - b_i )/(N-1)\n",
    "    return count\n",
    "\n",
    "\n",
    "print('-------------------------------------------------')\n",
    "print('Central point of dominance en grafos dirigidos')\n",
    "print('-------------------------------------------------')\n",
    "for city, graph in capitals.items():\n",
    "    try:\n",
    "        print(city+str(': ')+str(central_point_dominance(graph)))\n",
    "        print('')\n",
    "    except:\n",
    "        print(city+str(': ')+str(float('inf')))\n",
    "        print('')\n",
    "\n",
    "print('-------------------------------------------------')\n",
    "print('Central point of dominance en grafos no dirigidos')\n",
    "print('-------------------------------------------------')\n",
    "\n",
    "cpds=[]\n",
    "for city, graph in capitals.items():\n",
    "    try:\n",
    "        cpd=central_point_dominance(graph.to_undirected())\n",
    "        print(city+str(': ')+str(cpd))\n",
    "        cpds.append(cpd)\n",
    "        print('')\n",
    "    except:\n",
    "        print(city+str(': ')+str(float('inf')))\n",
    "        print('') \n",
    "\n",
    "cpds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# Spectral Radius\n",
    "#--------------------------------\n",
    "#     the smaller the spectral radius rho, the higher the probability of 'virus infection' tau, \n",
    "#     the more difficult it is for an idea to spread in the innovative network, \n",
    "#     namely, the less efficient\n",
    "\n",
    "import numpy.linalg\n",
    "\n",
    "def spectral_radius(G):\n",
    "    L = nx.normalized_laplacian_matrix(G)\n",
    "    e = numpy.linalg.eigvals(L.A)\n",
    "    e_abs = [abs(x) for x in e]\n",
    "    return max(e_abs)\n",
    "\n",
    "\n",
    "print('-------------------------------------------------')\n",
    "print('Radio Espectral en grafos dirigidos')\n",
    "print('-------------------------------------------------')\n",
    "for city, graph in capitals.items():\n",
    "    try:\n",
    "        print(city+str(': ')+str(spectral_radius(graph)))\n",
    "        print('')\n",
    "    except:\n",
    "        print(city+str(': ')+str(float('inf')))\n",
    "        print('')\n",
    "\n",
    "print('-------------------------------------------------')\n",
    "print('Radio Espectral en grafos no dirigidos')\n",
    "print('-------------------------------------------------')\n",
    "\n",
    "spectral_radii = []\n",
    "for city, graph in capitals.items():\n",
    "    try:\n",
    "        sr=spectral_radius(graph.to_undirected())\n",
    "        spectral_radii.append(sr)\n",
    "        print(city+str(': ')+str(sr))\n",
    "        print('')\n",
    "    except:\n",
    "        print(city+str(': ')+str(float('inf')))\n",
    "        print('') \n",
    "\n",
    "print(spectral_radii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_ratio(G):\n",
    "    return len(nx.k_core(G,k=2).nodes())/len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rich_club_coeffs(G):\n",
    "    t_ok = True\n",
    "    t = 0\n",
    "    d = dict()\n",
    "    while t_ok:\n",
    "        nodes_large_degree=[]\n",
    "        for x in G.nodes():\n",
    "            if G.degree(x)>t:\n",
    "                nodes_large_degree.append(x)\n",
    "        core = G.subgraph(nodes_large_degree)\n",
    "        edges_core = len(core.edges())\n",
    "        nodes_core = len(core.nodes())\n",
    "        if nodes_core<=1:\n",
    "            t_ok = False\n",
    "            break\n",
    "        d[t] = (2*edges_core)/(nodes_core*(nodes_core-1))\n",
    "        t += 1 \n",
    "    return d        \n",
    "\n",
    "def max_rich_club(G):\n",
    "    #rich_club_1=nx.algorithms.rich_club_coefficient(G, normalized=False)\n",
    "    rich_club=rich_club_coeffs(G)\n",
    "    max_i=0\n",
    "    \n",
    "    for i in range(len(rich_club)):\n",
    "        if rich_club[i]>rich_club[max_i]:\n",
    "            max_i=i\n",
    "    #print(max_i)\n",
    "    return rich_club[max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>País</th>\n",
       "      <th>avg strength</th>\n",
       "      <th>weight</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Weighted Degree</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>clustering</th>\n",
       "      <th>Diámetro</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Camino más corto promedio</th>\n",
       "      <th>Transitividad</th>\n",
       "      <th>Eficiencia Global</th>\n",
       "      <th>Small Worldness</th>\n",
       "      <th>Rich Club Coefficient</th>\n",
       "      <th>Core Ratio</th>\n",
       "      <th>Central Point Dominance</th>\n",
       "      <th>Spectral radius</th>\n",
       "      <th>Modularidad con pesos (1.0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CABA</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>3.244633</td>\n",
       "      <td>1.481579</td>\n",
       "      <td>4.385965</td>\n",
       "      <td>14.017544</td>\n",
       "      <td>4.798246</td>\n",
       "      <td>0.148791</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.355669</td>\n",
       "      <td>0.107392</td>\n",
       "      <td>0.325773</td>\n",
       "      <td>0.960807</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.495614</td>\n",
       "      <td>0.251</td>\n",
       "      <td>1.868</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDMX</td>\n",
       "      <td>México</td>\n",
       "      <td>3.477388</td>\n",
       "      <td>1.388629</td>\n",
       "      <td>3.658863</td>\n",
       "      <td>12.963211</td>\n",
       "      <td>5.622074</td>\n",
       "      <td>0.075940</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3.820318</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.289320</td>\n",
       "      <td>0.677149</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.421405</td>\n",
       "      <td>0.202</td>\n",
       "      <td>1.910</td>\n",
       "      <td>0.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santiago de Chile</td>\n",
       "      <td>Chile</td>\n",
       "      <td>3.417211</td>\n",
       "      <td>1.462564</td>\n",
       "      <td>3.948718</td>\n",
       "      <td>13.764103</td>\n",
       "      <td>5.041026</td>\n",
       "      <td>0.134037</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.227544</td>\n",
       "      <td>0.100744</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.906814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.525</td>\n",
       "      <td>1.890</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Montevideo</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>3.227742</td>\n",
       "      <td>2.749495</td>\n",
       "      <td>7.747475</td>\n",
       "      <td>25.939394</td>\n",
       "      <td>4.479798</td>\n",
       "      <td>0.207747</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.081116</td>\n",
       "      <td>0.224523</td>\n",
       "      <td>0.360837</td>\n",
       "      <td>1.274519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.778</td>\n",
       "      <td>0.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Madrid</td>\n",
       "      <td>España</td>\n",
       "      <td>3.518387</td>\n",
       "      <td>1.362343</td>\n",
       "      <td>3.790795</td>\n",
       "      <td>12.861925</td>\n",
       "      <td>6.079498</td>\n",
       "      <td>0.120510</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3.783517</td>\n",
       "      <td>0.081917</td>\n",
       "      <td>0.294653</td>\n",
       "      <td>1.141033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.439331</td>\n",
       "      <td>0.184</td>\n",
       "      <td>1.920</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>3.430669</td>\n",
       "      <td>1.253704</td>\n",
       "      <td>3.370370</td>\n",
       "      <td>11.694444</td>\n",
       "      <td>6.726852</td>\n",
       "      <td>0.129928</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4.324031</td>\n",
       "      <td>0.078571</td>\n",
       "      <td>0.266719</td>\n",
       "      <td>1.211794</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.421296</td>\n",
       "      <td>0.237</td>\n",
       "      <td>1.983</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Ciudad       País  avg strength    weight    Degree  \\\n",
       "0               CABA  Argentina      3.244633  1.481579  4.385965   \n",
       "1               CDMX     México      3.477388  1.388629  3.658863   \n",
       "2  Santiago de Chile      Chile      3.417211  1.462564  3.948718   \n",
       "3         Montevideo    Uruguay      3.227742  2.749495  7.747475   \n",
       "4             Madrid     España      3.518387  1.362343  3.790795   \n",
       "5          Sao Paulo     Brasil      3.430669  1.253704  3.370370   \n",
       "\n",
       "   Weighted Degree  Eccentricity  clustering  Diámetro  Radio  \\\n",
       "0        14.017544      4.798246    0.148791         6      3   \n",
       "1        12.963211      5.622074    0.075940         7      4   \n",
       "2        13.764103      5.041026    0.134037         6      3   \n",
       "3        25.939394      4.479798    0.207747         6      3   \n",
       "4        12.861925      6.079498    0.120510         8      5   \n",
       "5        11.694444      6.726852    0.129928         8      4   \n",
       "\n",
       "   Camino más corto promedio  Transitividad  Eficiencia Global  \\\n",
       "0                   3.355669       0.107392           0.325773   \n",
       "1                   3.820318       0.050000           0.289320   \n",
       "2                   3.227544       0.100744           0.338889   \n",
       "3                   3.081116       0.224523           0.360837   \n",
       "4                   3.783517       0.081917           0.294653   \n",
       "5                   4.324031       0.078571           0.266719   \n",
       "\n",
       "   Small Worldness  Rich Club Coefficient  Core Ratio  \\\n",
       "0         0.960807               0.866667    0.495614   \n",
       "1         0.677149               0.361111    0.421405   \n",
       "2         0.906814               1.000000    0.430769   \n",
       "3         1.274519               1.000000    0.565657   \n",
       "4         1.141033               1.000000    0.439331   \n",
       "5         1.211794               0.222222    0.421296   \n",
       "\n",
       "   Central Point Dominance  Spectral radius  Modularidad con pesos (1.0)  \n",
       "0                    0.251            1.868                        0.524  \n",
       "1                    0.202            1.910                        0.628  \n",
       "2                    0.525            1.890                        0.530  \n",
       "3                    0.179            1.778                        0.611  \n",
       "4                    0.184            1.920                        0.610  \n",
       "5                    0.237            1.983                        0.682  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitals = {'CABA': caba_G, 'CDMX':cdmx_G, 'Santiago de Chile': scl_G, 'Montevideo': mtv_G, 'Madrid': mad_G, 'Sao Paulo': sao_G}\n",
    "\n",
    "#las columnas que vamos a aregar al DataFrame\n",
    "diameter = [0]*len(capitals)\n",
    "radius = [0]*len(capitals)\n",
    "avg_shortest_path_length = [0]*len(capitals)\n",
    "transitivity = [0]*len(capitals)\n",
    "global_efficiency = [0]*len(capitals)\n",
    "modularity = [0]*len(capitals)\n",
    "\n",
    "small_worldness = [0.9608066521709907, \n",
    "                  0.6771493264436462,\n",
    "                  0.906813593858747,\n",
    "                  1.2745185062977642,\n",
    "                  1.1410329702664386,\n",
    "                  1.211793728337516]  \n",
    "\n",
    "rich_club_coefficient = [0]*len(capitals)\n",
    "# trophic_incoherence= [0]*len(capitals)\n",
    "# assort_coeff = [0]*len(capitals)\n",
    "core_rate= [0]*len(capitals)\n",
    "\n",
    "for city, graph in capitals.items():\n",
    "    city_index=df_concat.index[df_concat['Ciudad']==city].tolist()[0]\n",
    "    \n",
    "    #conseguimos cada parámetro para esta ciudad\n",
    "    undirected=nx.to_undirected(graph)\n",
    "    diameter[city_index] =                     nx.diameter(undirected)\n",
    "    radius[city_index] =                       nx.radius(undirected)\n",
    "    avg_shortest_path_length[city_index] =     nx.average_shortest_path_length(undirected)\n",
    "    transitivity[city_index] =                 nx.transitivity(undirected)\n",
    "    global_efficiency[city_index] =            nx.global_efficiency(undirected)\n",
    "    #small_worldness precomputado\n",
    "    #modularidad precomputada\n",
    "    rich_club_coefficient[city_index] =        max_rich_club(undirected)  \n",
    "    #trophic_incoherence[city_index]=          nx.algorithms.centrality.trophic_incoherence_parameter(graph)\n",
    "    #assort_coeff[city_index]=                 nx.algorithms.degree_assortativity_coefficient(graph)\n",
    "    core_rate[city_index]=                     core_ratio(undirected)\n",
    "\n",
    "\n",
    "    \n",
    "df_concat['Diámetro'] = diameter\n",
    "df_concat['Radio'] = radius\n",
    "df_concat['Camino más corto promedio'] = avg_shortest_path_length\n",
    "df_concat['Transitividad'] = transitivity\n",
    "df_concat['Eficiencia Global'] = global_efficiency\n",
    "df_concat['Small Worldness'] = small_worldness\n",
    "df_concat['Rich Club Coefficient'] = rich_club_coefficient\n",
    "#df_concat['Trophic Incoherence'] = trophic_incoherence\n",
    "#df_concat['Coeficiente de Asortatividad'] = assort_coeff\n",
    "df_concat['Core Ratio'] = core_rate\n",
    "df_concat['Central Point Dominance'] = [round(elem,3) for elem in cpds]\n",
    "df_concat['Spectral radius'] = [round(elem,3) for elem in spectral_radii]\n",
    "\n",
    "df_concat['Modularidad con pesos (1.0)'] = [0.524, 0.628, 0.530, 0.611, 0.610, 0.682]\n",
    "\n",
    "\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>País</th>\n",
       "      <th>avg strength</th>\n",
       "      <th>weight</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Weighted Degree</th>\n",
       "      <th>Eccentricidad</th>\n",
       "      <th>Clustering</th>\n",
       "      <th>Diámetro</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Camino más corto promedio</th>\n",
       "      <th>Transitividad</th>\n",
       "      <th>Eficiencia Global</th>\n",
       "      <th>Small Worldness</th>\n",
       "      <th>Rich Club Coefficient</th>\n",
       "      <th>Core Ratio</th>\n",
       "      <th>Central Point Dominance</th>\n",
       "      <th>Spectral radius</th>\n",
       "      <th>Modularidad con pesos (1.0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CABA</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>3.244633</td>\n",
       "      <td>1.481579</td>\n",
       "      <td>4.385965</td>\n",
       "      <td>14.017544</td>\n",
       "      <td>4.798246</td>\n",
       "      <td>0.148791</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.355669</td>\n",
       "      <td>0.107392</td>\n",
       "      <td>0.325773</td>\n",
       "      <td>0.960807</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.495614</td>\n",
       "      <td>0.251</td>\n",
       "      <td>1.868</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDMX</td>\n",
       "      <td>México</td>\n",
       "      <td>3.477388</td>\n",
       "      <td>1.388629</td>\n",
       "      <td>3.658863</td>\n",
       "      <td>12.963211</td>\n",
       "      <td>5.622074</td>\n",
       "      <td>0.075940</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3.820318</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.289320</td>\n",
       "      <td>0.677149</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.421405</td>\n",
       "      <td>0.202</td>\n",
       "      <td>1.910</td>\n",
       "      <td>0.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santiago de Chile</td>\n",
       "      <td>Chile</td>\n",
       "      <td>3.417211</td>\n",
       "      <td>1.462564</td>\n",
       "      <td>3.948718</td>\n",
       "      <td>13.764103</td>\n",
       "      <td>5.041026</td>\n",
       "      <td>0.134037</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.227544</td>\n",
       "      <td>0.100744</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.906814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.525</td>\n",
       "      <td>1.890</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Montevideo</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>3.227742</td>\n",
       "      <td>2.749495</td>\n",
       "      <td>7.747475</td>\n",
       "      <td>25.939394</td>\n",
       "      <td>4.479798</td>\n",
       "      <td>0.207747</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.081116</td>\n",
       "      <td>0.224523</td>\n",
       "      <td>0.360837</td>\n",
       "      <td>1.274519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.778</td>\n",
       "      <td>0.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Madrid</td>\n",
       "      <td>España</td>\n",
       "      <td>3.518387</td>\n",
       "      <td>1.362343</td>\n",
       "      <td>3.790795</td>\n",
       "      <td>12.861925</td>\n",
       "      <td>6.079498</td>\n",
       "      <td>0.120510</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3.783517</td>\n",
       "      <td>0.081917</td>\n",
       "      <td>0.294653</td>\n",
       "      <td>1.141033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.439331</td>\n",
       "      <td>0.184</td>\n",
       "      <td>1.920</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>3.430669</td>\n",
       "      <td>1.253704</td>\n",
       "      <td>3.370370</td>\n",
       "      <td>11.694444</td>\n",
       "      <td>6.726852</td>\n",
       "      <td>0.129928</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4.324031</td>\n",
       "      <td>0.078571</td>\n",
       "      <td>0.266719</td>\n",
       "      <td>1.211794</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.421296</td>\n",
       "      <td>0.237</td>\n",
       "      <td>1.983</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Ciudad       País  avg strength    weight    Degree  \\\n",
       "0               CABA  Argentina      3.244633  1.481579  4.385965   \n",
       "1               CDMX     México      3.477388  1.388629  3.658863   \n",
       "2  Santiago de Chile      Chile      3.417211  1.462564  3.948718   \n",
       "3         Montevideo    Uruguay      3.227742  2.749495  7.747475   \n",
       "4             Madrid     España      3.518387  1.362343  3.790795   \n",
       "5          Sao Paulo     Brasil      3.430669  1.253704  3.370370   \n",
       "\n",
       "   Weighted Degree  Eccentricidad  Clustering  Diámetro  Radio  \\\n",
       "0        14.017544       4.798246    0.148791         6      3   \n",
       "1        12.963211       5.622074    0.075940         7      4   \n",
       "2        13.764103       5.041026    0.134037         6      3   \n",
       "3        25.939394       4.479798    0.207747         6      3   \n",
       "4        12.861925       6.079498    0.120510         8      5   \n",
       "5        11.694444       6.726852    0.129928         8      4   \n",
       "\n",
       "   Camino más corto promedio  Transitividad  Eficiencia Global  \\\n",
       "0                   3.355669       0.107392           0.325773   \n",
       "1                   3.820318       0.050000           0.289320   \n",
       "2                   3.227544       0.100744           0.338889   \n",
       "3                   3.081116       0.224523           0.360837   \n",
       "4                   3.783517       0.081917           0.294653   \n",
       "5                   4.324031       0.078571           0.266719   \n",
       "\n",
       "   Small Worldness  Rich Club Coefficient  Core Ratio  \\\n",
       "0         0.960807               0.866667    0.495614   \n",
       "1         0.677149               0.361111    0.421405   \n",
       "2         0.906814               1.000000    0.430769   \n",
       "3         1.274519               1.000000    0.565657   \n",
       "4         1.141033               1.000000    0.439331   \n",
       "5         1.211794               0.222222    0.421296   \n",
       "\n",
       "   Central Point Dominance  Spectral radius  Modularidad con pesos (1.0)  \n",
       "0                    0.251            1.868                        0.524  \n",
       "1                    0.202            1.910                        0.628  \n",
       "2                    0.525            1.890                        0.530  \n",
       "3                    0.179            1.778                        0.611  \n",
       "4                    0.184            1.920                        0.610  \n",
       "5                    0.237            1.983                        0.682  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cambiar los nombres de los atributos del DataFrame\n",
    "#algunos nombres de columnas no fueron modificados para facilitar legibilidad\n",
    "df_concat.rename(columns={'Eccentricity': 'Eccentricidad', 'clustering':'Clustering'}, inplace=True)\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.to_csv('Tidy_DataFrame.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando el caso de Oaxaca y Santiago de Chile\n",
    "\n",
    "Una de las observaciones que hizo el equipo de GED fue acerca de las redes de Oaxaca y Santiago de Chile. En Oaxaca, el nodo más prominente es IODEMC, mientras que en SCL el nodo más prominente es CORFO. Ambos nodos presentan mayor número de menciones, mayor número de flechas dirigidas hacia dichos nodos, y mayor grado. Por ende, estos nodos también resultan prominentes en casi todas las métricas nodales.\n",
    "\n",
    "Sin embargo, al remover IODEMC de Oaxaca, la red se desestabiliza, mientras que al remover CORFO de SCL, la red no logra desestabilizarse tanto como la red previa.\n",
    "\n",
    "En las siguientes medidas tomadas, se utilizará la construcción de multigrafo cuando sea posible, con el fin de dar importancia a una pareja de instituciones colaborando más de una vez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean \n",
    "from statistics import stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def armar_multigrafo(nodes,edges,rol_str,weight_str):\n",
    "    '''\n",
    "    Función con la cual, a partir de una lista de nodos y conexiones, forma un grafo con NetworkX\n",
    "    \n",
    "    In:\n",
    "    - nodes       lista de nodos\n",
    "    - edges       lista de aristas\n",
    "    - rol_str     un nombre para el parámetro que describe el rol de un actor\n",
    "    - weight_str  un nombre para el parámetro que describe el peso de las aristas\n",
    "    \n",
    "    Out\n",
    "    Un MultiDiGrafo NetworkX llamado G.\n",
    "    '''\n",
    "    \n",
    "    #crea un grafo dirigido a partir de la lista edges\n",
    "    G=nx.from_pandas_edgelist(edges,'Source','Target',edge_attr=[\"Weight\"],create_using=nx.MultiDiGraph())\n",
    "\n",
    "    #rol es un diccionario que manda cada id de un nodo a el atributo correspondiente a rol\n",
    "    rol = {nid: nodes[nodes['Id']==nid][rol_str].values[0] for nid in nodes['Id']}\n",
    "    nx.set_node_attributes(G,rol,'rol')\n",
    "    \n",
    "    #weight es un diccionario que manda cada id de un nodo a el atributo correspondiente al peso de nodo\n",
    "    weight = {nid: nodes[nodes['Id']==nid][weight_str].values[0] for nid in nodes['Id']}\n",
    "    nx.set_node_attributes(G,weight,'weight')\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "oax_G_m=armar_multigrafo(oax_nd,oax_ed,'rol','weight')\n",
    "scl_G_m=armar_multigrafo(scl_nd,scl_ed,'type','weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triángulos alrededor de IODEMC: 37\n",
      "Triángulos alrededor de CORFO: 77\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "# Triangles\n",
    "#------------------------\n",
    "\n",
    "#obtaining IODEMC's triangle number in OAX's network\n",
    "print( 'Triángulos alrededor de IODEMC: '+str(nx.triangles(oax_G.to_undirected(), 'IODEMC')) )\n",
    "\n",
    "#obtaining CORFO's triangle number in SCL's network\n",
    "print( 'Triángulos alrededor de CORFO: '+str(nx.triangles(scl_G.to_undirected(), 'CORFO')) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camino más corto promedio hacia IODEMC: 2.2134831460674156\n",
      "Camino más corto promedio hacia CORFO: 2.973333333333333\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "# Path length\n",
    "#------------------------\n",
    "#average shortest path length from any other node to our nodes of interest.\n",
    "\n",
    "#obtaining IODEMC's path length in OAX's network\n",
    "print( 'Camino más corto promedio hacia IODEMC: '+str( mean(nx.shortest_path_length(oax_G, 'IODEMC').values()) ) )\n",
    "\n",
    "#obtaining CORFO's path length in SCL's network\n",
    "print( 'Camino más corto promedio hacia CORFO: '+str( mean(nx.shortest_path_length(scl_G, 'CORFO').values()) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eficiencia global de IODEMC: 2.2386363636363638\n",
      "Eficiencia Global de CORFO: 2.9932885906040267\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "# Global efficiency\n",
    "#------------------------\n",
    "#average shortest path length from any other node to our nodes of interest.\n",
    "\n",
    "#obtaining IODEMC's global efficiency in OAX's network\n",
    "shortest_path_lengths_oax = nx.shortest_path_length(oax_G, 'IODEMC')\n",
    "del (shortest_path_lengths_oax['IODEMC'])\n",
    "print( 'Eficiencia global de IODEMC: '+str(mean(shortest_path_lengths_oax.values())) ) \n",
    "\n",
    "#obtaining CORFO's global efficiency in SCL's network\n",
    "shortest_path_lengths_scl = nx.shortest_path_length(scl_G, 'CORFO')\n",
    "del (shortest_path_lengths_scl['CORFO'])\n",
    "print( 'Eficiencia Global de CORFO: '+ str(mean(shortest_path_lengths_scl.values())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6862745098039216\n",
      "0.43733333333333335\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "# Local efficiency\n",
    "#------------------------\n",
    "#average shortest path length from any neighbor node to our nodes of interest.\n",
    "\n",
    "def nodes_connected(G, u, v):\n",
    "    return u in G.neighbors(v)\n",
    "\n",
    "\n",
    "#obtaining IODEMC's global efficiency in OAX's network\n",
    "shortest_paths_ngb_oax = {key:value for key,value in shortest_path_lengths_oax.items() if \n",
    "                          nodes_connected(oax_G, 'IODEMC', key)}\n",
    "print( mean([1/x for x in shortest_paths_ngb_oax.values()]) ) \n",
    "\n",
    "#obtaining CORFO's global efficiency in SCL's network\n",
    "shortest_paths_ngb_scl = {key:value for key,value in shortest_path_lengths_scl.items() if \n",
    "                          nodes_connected(scl_G, 'CORFO', key)}\n",
    "print( mean([1/x for x in shortest_paths_ngb_scl.values()]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_i = 2\n",
      "K_Si = 0.42105263157894735\n",
      "Sigma_Si = 0.7685331969757723\n",
      "IODEMCs within module z-score is: 2.054494684984738\n",
      "-----------------------------------------------\n",
      "K_i = 2\n",
      "K_Si = 0.46153846153846156\n",
      "Sigma_Si = 1.5028178660308569\n",
      "CORFOs within module z-score is: 1.0237178923915917\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "# Within module z-score\n",
    "#------------------------\n",
    "#   Degree to which a node is connected to other nodes inside the same community\n",
    "#   Helper functions:\n",
    "\n",
    "def nodes_connected(G, u, v):\n",
    "    return u in G.neighbors(v)\n",
    "\n",
    "def deg_in_module(G, M, v):\n",
    "    #degree of node inside its community\n",
    "    k=0\n",
    "    for x in M:\n",
    "        if nodes_connected(G, v, x) or nodes_connected(G, x, v): k+=G.number_of_edges(v,x)\n",
    "    return k\n",
    "\n",
    "\n",
    "#    Node:       IODEMC\n",
    "#    Network:    oax_G\n",
    "#    Community:  Articulators\n",
    "\n",
    "articulators = [x for x,y in oax_G.nodes(data=True) if y['rol']=='Articulador']\n",
    "ki = deg_in_module(oax_G, articulators, 'IODEMC')                                 #deg in module of IODEMC\n",
    "in_mod_degrees = [deg_in_module(oax_G, articulators, v) for v in articulators ]\n",
    "ksi = mean(in_mod_degrees)                                                        #average degree \n",
    "sigmasi = stdev(in_mod_degrees)                                                   #standard deviation of degrees\n",
    "\n",
    "\n",
    "print('K_i = '+str(ki) )\n",
    "print('K_Si = '+str(ksi) )\n",
    "print('Sigma_Si = '+str(sigmasi) )\n",
    "print('IODEMCs within module z-score is: '+ str((ki-ksi)/sigmasi) )\n",
    "print('-----------------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "#    Node:       CORFO\n",
    "#    Network:    oax_G\n",
    "#    Community:  Articulators\n",
    "\n",
    "articulators = [x for x,y in scl_G.nodes(data=True) if y['rol']=='Articulador']\n",
    "ki = deg_in_module(scl_G, articulators, 'CORFO')                                 #deg in module of IODEMC\n",
    "in_mod_degrees = [deg_in_module(scl_G, articulators, v) for v in articulators ]\n",
    "ksi = mean(in_mod_degrees)                                                        #average degree \n",
    "sigmasi = stdev(in_mod_degrees)                                                   #standard deviation of degrees\n",
    "\n",
    "\n",
    "print('K_i = '+str(ki) )\n",
    "print('K_Si = '+str(ksi) )\n",
    "print('Sigma_Si = '+str(sigmasi) )\n",
    "print('CORFOs within module z-score is: '+ str((ki-ksi)/sigmasi) )\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "IODEMCs participation coefficient is: 0.9318750000000001\n",
      "-----------------------------------------------\n",
      "56\n",
      "CORFOs participation coefficient is: 0.8785076530612245\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#----------------------------\n",
    "# Participation coefficient\n",
    "#----------------------------\n",
    "#   Relation between edges connecting node with other communities, and total number of edges from node\n",
    "#   Helper functions:\n",
    "\n",
    "def nodes_connected(G, u, v):\n",
    "    return u in G.neighbors(v)\n",
    "\n",
    "def deg_in_module(G, M, v):\n",
    "    #degree of node inside its community\n",
    "    k=0\n",
    "    for x in M:\n",
    "        if nodes_connected(G, v, x) or nodes_connected(G, x, v): k+=G.number_of_edges(v,x)\n",
    "    return k\n",
    "\n",
    "\n",
    "#    Node:       IODEMC\n",
    "#    Network:    oax_G\n",
    "#    Community:  Articulators\n",
    "\n",
    "roles=['Articulador', 'Habilitador', 'Generador de conocimiento', 'Vinculador', 'Comunidad', 'Promotor']\n",
    "communities = {rol: [x for x,y in oax_G.nodes(data=True) if y['rol']==rol] for rol in roles}\n",
    "d = oax_G.degree('IODEMC')\n",
    "print(d)\n",
    "p=1\n",
    "for rol in roles:\n",
    "    p -= (deg_in_module(oax_G, communities[rol], 'IODEMC'))**2 / d**2    #we want to check degree of 'IODEMC' \n",
    "\n",
    "print('IODEMCs participation coefficient is: '+ str(p) )\n",
    "print('-----------------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "#    Node:       CORFO\n",
    "#    Network:    oax_G\n",
    "#    Community:  Articulators\n",
    "\n",
    "roles=['Articulador', 'Habilitador', 'Generador de conocimiento', 'Vinculador', 'Comunidad', 'Promotor']\n",
    "communities = {rol: [x for x,y in scl_G.nodes(data=True) if y['rol']==rol] for rol in roles}\n",
    "d = scl_G.degree('CORFO')\n",
    "print(d)\n",
    "p=1\n",
    "for rol in roles:\n",
    "    p -= (deg_in_module(scl_G, communities[rol], 'CORFO'))**2 / d**2    #we want to check degree of 'IODEMC' \n",
    "\n",
    "print('CORFOs participation coefficient is: '+ str(p) )\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modularidad de acuerdo a roles de los actores\n",
    "\n",
    "En la siguiente parte del código, exploramos cuál puede ser la modularidad de los grafos que estamos estudiando, cuando las comunidades están definidas por los roles que tiene cada actor, que puede ser:\n",
    "* Articulador\n",
    "* Habilitador\n",
    "* Generador de Conocimiento\n",
    "* Vinculador\n",
    "* Comunidad\n",
    "* Promotor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CABA\n",
      "0.035565432098762985\n",
      "\n",
      "CDMX\n",
      "-0.0007892544773022074\n",
      "\n",
      "Santiago de Chile\n",
      "0.032705075660665925\n",
      "\n",
      "Montevideo\n",
      "0.028866354019671435\n",
      "\n",
      "Madrid\n",
      "0.06996407631681234\n",
      "\n",
      "Sao Paulo\n",
      "0.025638685298599303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------\n",
    "# Modularities when modules are the roles\n",
    "#----------------------------------------\n",
    "roles_esp={'Articulador':0, 'Habilitador':1, 'Generador de conocimiento':2, 'Vinculador':3, 'Comunidad':4, 'Promotor':5}\n",
    "roles_esp_2={'Articulador':0, 'Habilitador':1, 'Generador de Conocimiento':2, 'Vinculador':3, 'Comunidad':4, 'Promotor':5}\n",
    "roles_ing={'Articulator':0, 'Enabler':1, 'Knowledge Generator':2, 'Linker':3, 'Community':4, 'Promoter':5}\n",
    "\n",
    "role_modularity = [0]*len(capitals)\n",
    "\n",
    "for city, graph in capitals.items():\n",
    "    print(city)\n",
    "    G = nx.to_undirected(graph)\n",
    "    city_index = df_concat.index[df_concat['Ciudad']==city].tolist()[0]\n",
    "    communities=[]\n",
    "    \n",
    "    if city == 'Montevideo':\n",
    "        #we need to use role names in English\n",
    "        index_partition = {rol: [] for rol in roles_ing.keys()}\n",
    "        for node,data in G.nodes(data=True):\n",
    "            index_partition[data['rol']].append(node)\n",
    "        for rol,listy in index_partition.items():\n",
    "            communities.append(set(listy))\n",
    "            \n",
    "        #for rol, index in roles_ing.items():\n",
    "        #    communities[index]=communities.pop(rol)\n",
    "    elif city in ['Santiago de Chile','Madrid', 'Sao Paulo']:\n",
    "        #we need to use role names in English\n",
    "        index_partition = {rol: [] for rol in roles_esp_2.keys()}\n",
    "        for node,data in G.nodes(data=True):\n",
    "            index_partition[data['rol']].append(node)\n",
    "        for rol,listy in index_partition.items():\n",
    "            communities.append(set(listy))\n",
    "    else:\n",
    "        #communities = {rol: [x for x,y in scl_G.nodes(data=True) if y['rol']==rol] for rol in roles_esp}\n",
    "        # we can use role names in Spanish\n",
    "        #we need to use role names in English\n",
    "        index_partition = {rol: [] for rol in roles_esp.keys()}\n",
    "        for node,data in G.nodes(data=True):\n",
    "            index_partition[data['rol']].append(node)\n",
    "        for rol,listy in index_partition.items():\n",
    "            communities.append(set(listy))\n",
    "    \n",
    "    role_modularity[city_index]=nx.algorithms.community.modularity(G,communities)\n",
    "    print(role_modularity[city_index])\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(listy):\n",
    "    n , sumsquares = len(listy), 0\n",
    "    for x in listy:\n",
    "        sumsquares += x**2\n",
    "    avgsquares = sumsquares/n\n",
    "    return avgsquares**0.5\n",
    "def onefive_normalize(listy):\n",
    "    newlist = []\n",
    "    for x in listy:\n",
    "        newlist.append((x-1)/4)\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5667012250096545, 0.4054433900475786, 0.6164340603346302, 0.6613123368957821, 0.6330815474563322, 0.500778743243129]\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------\n",
    "# Primera fórmula para colaboratividad\n",
    "#---------------------------------------\n",
    "\n",
    "eg = df_concat['Eficiencia Global'].tolist()\n",
    "sw = df_concat['Small Worldness'].tolist()\n",
    "comunicacion = [0.5*(eg[x]+sw[x]) for x in range(6)]\n",
    "\n",
    "rcc = df_concat['Rich Club Coefficient'].tolist()\n",
    "as_ = onefive_normalize(df_concat['avg strength'].tolist())\n",
    "preparacion = [0.5*(rcc[x]+as_[x]) for x in range(6)]\n",
    "\n",
    "\n",
    "cl = df_concat['Clustering'].tolist()\n",
    "cpd = df_concat['Central Point Dominance'].tolist()\n",
    "resiliencia = [0.5*(cl[x]+cpd[x]) for x in range(6)]\n",
    "\n",
    "colab_1 = [rms([comunicacion[x], preparacion[x], resiliencia[x]]) for x in range(6)]\n",
    "print(colab_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
