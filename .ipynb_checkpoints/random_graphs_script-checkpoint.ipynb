{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Random Graph generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_graph(prob_resp,prob_nuevo):\n",
    "    \"\"\"\n",
    "    prob_resp float    define la probabilidad de que al tomar un nodo este haya sido un respondiente de la encuesta\n",
    "    prob_nuevo float   define la probabilidad de que un respondiente tenga conexiones con nodos nuevos\n",
    "\n",
    "    Esta funcion genera graficas aleatorias basadas en el metodo con el que se crearon las networks de emprendimiento\n",
    "    \"\"\"\n",
    "    G=nx.Graph()\n",
    "    queue=[\"0\"]\n",
    "    max_index=0\n",
    "    max_respondents=random.randint(20,30)             #Indicador que nos dice cuantos respondientes puede haber\n",
    "    respondents=0\n",
    "    while len(queue)!=0:\n",
    "        if (random.random()<prob_resp and respondents<max_respondents) or queue[0]==\"0\":      #Crear conexiones para un respondiente\n",
    "            respondents+=1\n",
    "            n=random.randint(6,21)\n",
    "            new_n=0\n",
    "            old_n=0\n",
    "            for i in range(n):                                              #Calcular cuantas conexiones son con nodos nuevos y cuantos con ya existentesz\n",
    "                if random.random()<prob_nuevo:\n",
    "                    new_n+=1\n",
    "                else:\n",
    "                    old_n+=1\n",
    "            for i in range(new_n):\n",
    "                new_node=str(i+max_index+1)\n",
    "                queue.append(new_node)\n",
    "                G.add_node(new_node)\n",
    "                G.add_edge(queue[0],new_node)\n",
    "            for i in range(old_n):\n",
    "                node=str(random.randint(0,int(queue[0]))-1)\n",
    "                G.add_edge(queue[0],node)\n",
    "            max_index+=new_n\n",
    "            queue.pop(0)\n",
    "        else:                                                                #Crear conexiones para los no respondientes\n",
    "            if random.random()<0.25:\n",
    "                n=random.randint(1,6)\n",
    "                for i in range(n):\n",
    "                    node=str(random.randint(0,int(queue[0]))-1)\n",
    "                    G.add_edge(queue[0],node)\n",
    "            queue.pop(0)\n",
    "    if len(G.nodes())<150 or len(G.nodes())>400:\n",
    "        return random_graph(prob_resp,prob_nuevo)\n",
    "    else:\n",
    "        return G\n",
    "    \n",
    "#for i in range(100):\n",
    "#    nx.write_graphml(random_graph(0.25,0.55+i/400),'Random_Graphs/Random_Graph_'+str(11+i)+'.graphml')\n",
    "#for i in range(100):\n",
    "#    nx.write_graphml(random_graph(0.25,0.55-i/400),'Random_Graphs/Random_Graph_'+str(111+i)+'.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "\n",
    "def are_adjacent(u,v,G):\n",
    "    if v not in G.nodes():\n",
    "        return False\n",
    "    elif v in G.neighbors(u):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def random_graph_2(n_evals, prob_out, prob_new):\n",
    "    '''\n",
    "    Generator of a random graph, given that n\n",
    "    Given a specific number of respondents of the questionnaire, and that each of them could have provided 25 responses maximum\n",
    "    \n",
    "    Input:\n",
    "     - n_evals  : number of evaluators responding questionnaire\n",
    "     - prob_out : probability that a mentionned collaboration is outside of the network of evaluators\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    G=nx.DiGraph()\n",
    "    setedges = set()\n",
    "    \n",
    "    inside = dict()\n",
    "    outside = dict()\n",
    "    \n",
    "    last_index = n_evals-1\n",
    "    \n",
    "    for i in range(n_evals):              #add all evaluators to the graph\n",
    "        G.add_node(i)\n",
    "        inside[i] = 0\n",
    "        \n",
    "    # evaluator |--> no. of collaborations,   in (0,25)~ normal distribution\n",
    "    sample_num_evaluations = np.random.normal(loc=12.3, scale=4, size=n_evals)\n",
    "    list_degrees_evaluators = [int(x) for x in sample_num_evaluations]\n",
    "    \n",
    "    for i in inside.keys():\n",
    "        for j in range(list_degrees_evaluators[i]):\n",
    "            \n",
    "            if random.random()<prob_out:           #edge added outside evaluators' list\n",
    "                if outside == dict():                              # if list outside evaluators is new\n",
    "                    last_index+=1\n",
    "                    to = last_index\n",
    "                    G.add_node(to)\n",
    "                    G.add_edge(i,to)\n",
    "                    setedges.add((i,to))\n",
    "                    outside[to] = 1\n",
    "                    inside[i] += 1\n",
    "                else:\n",
    "                    if random.random()<prob_new:               # if edge goes to a new vertex\n",
    "                        last_index+=1       \n",
    "                        to=last_index\n",
    "                        G.add_node(to)\n",
    "                        G.add_edge(i,to)\n",
    "                        setedges.add((i,to))\n",
    "                        outside[to] = 1\n",
    "                        inside[i] +=1\n",
    "                        \n",
    "                    else:\n",
    "                        vertices, degrees = [], []\n",
    "                        for vertex, degree in outside.items():\n",
    "                            if vertex!=i:\n",
    "                                vertices.append(vertex)\n",
    "                                degrees.append(degree+1)\n",
    "                        s = sum(degrees)\n",
    "                        w = [x/s for x in degrees]\n",
    "                        to = choice(vertices, size=1, p=w)[0]\n",
    "                        if are_adjacent(i,to,G):\n",
    "                            to = choice(vertices, size=1, p=w)[0]\n",
    "                        G.add_node(to)\n",
    "                        G.add_edge(i,to)\n",
    "                        setedges.add((i,to))\n",
    "                        outside[to]+=1\n",
    "                        inside[i]+=1\n",
    "                        \n",
    "            else:\n",
    "                vertices, degrees = [], []\n",
    "                for vertex, degree in inside.items():\n",
    "                    if vertex != i:\n",
    "                        vertices.append(vertex)\n",
    "                        degrees.append(degree+1)\n",
    "                s = sum(degrees)\n",
    "                w = [x/s for x in degrees]\n",
    "                to = choice(vertices, size=1, p=w)[0]\n",
    "                if are_adjacent(i,to,G):\n",
    "                    to = choice(vertices, size=1, p=w)[0]\n",
    "                G.add_node(to)\n",
    "                G.add_edge(i,to)\n",
    "                setedges.add((i,to))\n",
    "                inside[to]+=1\n",
    "                inside[i]+=1\n",
    "    return G         \n",
    "\n",
    "\n",
    "list_cities = ['Aguascalientes', 'Buenos Aires', 'Ciudad de México', 'Guadalajara', 'Hidalgo',\n",
    "                  'Madrid', 'Montevideo', 'Oaxaca', 'Sao Paulo', 'Santiago de Chile']\n",
    "num_evaluators = {'Aguascalientes':19, 'Buenos Aires':31, 'Ciudad de México':36, 'Guadalajara':32, 'Hidalgo':19,\n",
    "                  'Madrid':37, 'Montevideo':48, 'Oaxaca':36, 'Sao Paulo':28, 'Santiago de Chile':25}\n",
    "for city in list_cities:\n",
    "    G= random_graph_2(num_evaluators[city],0.2, 0.5)\n",
    "    nx.write_graphml(G,'Random_Graphs_Second_Type_Corrected/Random_Graph_'+city+'.graphml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Madrid</th>\n",
       "      <th>Madrid SG</th>\n",
       "      <th>Madrid Typeform</th>\n",
       "      <th>CDMX</th>\n",
       "      <th>Santiago</th>\n",
       "      <th>CABA</th>\n",
       "      <th>Sao Paulo</th>\n",
       "      <th>Montevideo</th>\n",
       "      <th>Oaxaca</th>\n",
       "      <th>GDL</th>\n",
       "      <th>Pachuca</th>\n",
       "      <th>AGS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muestra</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>59</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nodes</td>\n",
       "      <td>239</td>\n",
       "      <td>120</td>\n",
       "      <td>156</td>\n",
       "      <td>299</td>\n",
       "      <td>195</td>\n",
       "      <td>228</td>\n",
       "      <td>216</td>\n",
       "      <td>198</td>\n",
       "      <td>149</td>\n",
       "      <td>187</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Edges</td>\n",
       "      <td>453</td>\n",
       "      <td>166</td>\n",
       "      <td>205</td>\n",
       "      <td>547</td>\n",
       "      <td>385</td>\n",
       "      <td>500</td>\n",
       "      <td>364</td>\n",
       "      <td>767</td>\n",
       "      <td>326</td>\n",
       "      <td>474</td>\n",
       "      <td>254</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Promedio colabs. por participante</td>\n",
       "      <td>12.13</td>\n",
       "      <td>10.13</td>\n",
       "      <td>8.63</td>\n",
       "      <td>12.33</td>\n",
       "      <td>13.04</td>\n",
       "      <td>13.48</td>\n",
       "      <td>10.38</td>\n",
       "      <td>13.4</td>\n",
       "      <td>6.39</td>\n",
       "      <td>10.81</td>\n",
       "      <td>9.52</td>\n",
       "      <td>8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>% Muestra</td>\n",
       "      <td>15.90%</td>\n",
       "      <td>13.33%</td>\n",
       "      <td>15.38%</td>\n",
       "      <td>17.06%</td>\n",
       "      <td>15.38%</td>\n",
       "      <td>15.79%</td>\n",
       "      <td>15.74%</td>\n",
       "      <td>29.80%</td>\n",
       "      <td>24.16%</td>\n",
       "      <td>17.11%</td>\n",
       "      <td>16.80%</td>\n",
       "      <td>19.79%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Unnamed: 0  Madrid Madrid SG Madrid Typeform  \\\n",
       "0                            Muestra      38        16              24   \n",
       "1                              Nodes     239       120             156   \n",
       "2                              Edges     453       166             205   \n",
       "3  Promedio colabs. por participante   12.13     10.13            8.63   \n",
       "4                          % Muestra  15.90%    13.33%          15.38%   \n",
       "\n",
       "     CDMX Santiago    CABA Sao Paulo Montevideo  Oaxaca     GDL Pachuca  \\\n",
       "0      51       30      36        34         59      36      32      21   \n",
       "1     299      195     228       216        198     149     187     125   \n",
       "2     547      385     500       364        767     326     474     254   \n",
       "3   12.33    13.04   13.48     10.38       13.4    6.39   10.81    9.52   \n",
       "4  17.06%   15.38%  15.79%    15.74%     29.80%  24.16%  17.11%  16.80%   \n",
       "\n",
       "      AGS  \n",
       "0      19  \n",
       "1      96  \n",
       "2     233  \n",
       "3    8.21  \n",
       "4  19.79%  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muestra = pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - Muestra.csv')             \n",
    "\n",
    "\n",
    "ags_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - AGS.csv')             \n",
    "caba_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - CABA.csv')             \n",
    "cdmx_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - CDMX.csv')             \n",
    "gdl_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - GDL.csv')             \n",
    "hgo_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - HGO.csv')             \n",
    "mad_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - MAD.csv')             \n",
    "mtv_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - MVD.csv')             \n",
    "oax_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - OAX.csv')             \n",
    "sao_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - SAO.csv')             \n",
    "scl_info=pd.read_csv('Data_answers_evaluators/Evaluadores ecosistemas.xlsx - SCL.csv')  \n",
    "\n",
    "ags_info.rename(columns={'Unnamed: 1':'Colabs'}, inplace=True)\n",
    "gdl_info.rename(columns={'Unnamed: 1':'Colabs'}, inplace=True)\n",
    "hgo_info.rename(columns={'Unnamed: 1':'Colabs'}, inplace=True)\n",
    "oax_info.rename(columns={'Unnamed: 1':'Colabs'}, inplace=True)\n",
    "\n",
    "\n",
    "list_cities = ['AGS', 'CABA', 'CDMX', 'GDL', 'Pachuca',\n",
    "                  'Madrid', 'Montevideo', 'Oaxaca', 'Sao Paulo', 'Santiago']\n",
    "cities_info = {'AGS': ags_info, \n",
    "              'CABA' : caba_info,\n",
    "              'CDMX' : cdmx_info,\n",
    "              'GDL' : gdl_info,\n",
    "              'Pachuca' : hgo_info,\n",
    "              'Madrid' : mad_info,\n",
    "              'Montevideo' : mtv_info,\n",
    "              'Oaxaca' : oax_info,\n",
    "              'Sao Paulo' : sao_info,\n",
    "              'Santiago' : scl_info}\n",
    "\n",
    "muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''Third Random Graph Generator'''\n",
    "\n",
    "def eliminate_small_components(G):\n",
    "    '''\n",
    "    We make sure there are no disconnected components. \n",
    "    '''\n",
    "    to_remove = []\n",
    "    \n",
    "    for x in G.nodes():\n",
    "        if len(list(nx.node_connected_component(nx.to_undirected(G),x)))< 20 :\n",
    "            to_remove.append(x)\n",
    "    for x in to_remove:\n",
    "        G.remove_node(x)\n",
    "    \n",
    "    if nx.number_connected_components(nx.to_undirected(G))>1:\n",
    "        print('****')    \n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "def random_graph_3(infos, city, prob_out, prob_new):\n",
    "    '''\n",
    "    With this function, we are simulating the responses we obtained from each of the surveyed ecosystems/cities. \n",
    "    The information we have is, for each evaluator, how many \n",
    "    \n",
    "    Generator of a random graph, given the number of respondents of the questionnaire,\n",
    "    the number of evaluators of collaborations, and the number of collaborations reported by each of them.\n",
    "    \n",
    "    Input:\n",
    "     - infos : dictionary mapping from city to num_collab information\n",
    "     - city : name of city to be simulated\n",
    "     - prob_out : probability that a mentionned collaboration is outside of the network of evaluators\n",
    "     - prob_new : probability that a mentionned collaboration is a newly mentionned org\n",
    "     \n",
    "    '''\n",
    "    \n",
    "    G=nx.DiGraph()\n",
    "    setedges = set()\n",
    "    \n",
    "    \n",
    "    #degrees of nodes inside and outside respondent list\n",
    "    inside = dict()\n",
    "    outside = dict()\n",
    "    \n",
    "    \n",
    "    #determine number of organizations that answered and number of evaluators: \n",
    "    n_responded = int(muestra[city][0])\n",
    "    n_evals = len(list(infos[city]['Colabs']))\n",
    "    last_index = n_responded\n",
    "    \n",
    "    \n",
    "    #number of total nodes, and number of edges:                  #still don't know how to use\n",
    "    num_nodes = int(muestra[city][1])\n",
    "    num_edges = int(muestra[city][2])\n",
    "    \n",
    "    for i in range(last_index):              #add all evaluators to the graph\n",
    "        G.add_node(i)\n",
    "        if i in range(n_evals):\n",
    "            inside[i] = 0\n",
    "        else:\n",
    "            outside[i] = 0\n",
    "        \n",
    "    \n",
    "    for i in inside.keys():\n",
    "        \n",
    "        deg_i = infos[city]['Colabs'][i]         # the degree of that node is in the info retrieved\n",
    "        for j in range(deg_i):\n",
    "            \n",
    "            if random.random() < prob_out:           #edge added outside evaluators' list\n",
    "                if outside == dict():                              # if list outside evaluators is new\n",
    "                    #last_index+=1\n",
    "                    to = last_index\n",
    "                    G.add_node(to)\n",
    "                    G.add_edge(i,to)\n",
    "                    setedges.add((i,to))\n",
    "                    outside[to] = 1\n",
    "                    inside[i] += 1\n",
    "                else:\n",
    "                    if random.random()<prob_new:               # if edge goes to a new vertex\n",
    "                        last_index+=1       \n",
    "                        to=last_index\n",
    "                        G.add_node(to)\n",
    "                        G.add_edge(i,to)\n",
    "                        setedges.add((i,to))\n",
    "                        outside[to] = 1\n",
    "                        inside[i] +=1\n",
    "                        \n",
    "                    else:\n",
    "                        vertices, degrees = [], []\n",
    "                        for vertex, degree in outside.items():\n",
    "                            if vertex!=i:\n",
    "                                vertices.append(vertex)\n",
    "                                degrees.append(degree+1)\n",
    "                        s = sum(degrees)\n",
    "                        w = [x/s for x in degrees]\n",
    "                        to = choice(vertices, size=1, p=w)[0]\n",
    "                        if are_adjacent(i,to,G):\n",
    "                            to = choice(vertices, size=1, p=w)[0]\n",
    "                        G.add_edge(i,to)\n",
    "                        setedges.add((i,to))\n",
    "                        outside[to]+=1\n",
    "                        inside[i]+=1\n",
    "                        \n",
    "            else:\n",
    "                vertices, degrees = [], []\n",
    "                for vertex, degree in inside.items():\n",
    "                    if vertex != i:\n",
    "                        vertices.append(vertex)\n",
    "                        degrees.append(degree+1)\n",
    "                s = sum(degrees)\n",
    "                w = [x/s for x in degrees]\n",
    "                to = choice(vertices, size=1, p=w)[0]\n",
    "                if are_adjacent(i,to,G):\n",
    "                    to = choice(vertices, size=1, p=w)[0]\n",
    "                G.add_edge(i,to)\n",
    "                setedges.add((i,to))\n",
    "                inside[to]+=1\n",
    "                inside[i]+=1\n",
    "                \n",
    "    # now we have the degree of each evaluator covered, \n",
    "    # but also some of the orgs responded with\n",
    "    # 2 key orgs in their development and establishment\n",
    "    \n",
    "    for i in range(n_responded):\n",
    "        for j in range(2):\n",
    "\n",
    "            if random.random()<prob_out:           #edge added outside evaluators' list\n",
    "                if random.random()<prob_new:               # if edge goes to a new vertex\n",
    "                    last_index+=1       \n",
    "                    to=last_index\n",
    "                    G.add_node(to)\n",
    "                    G.add_edge(i,to)\n",
    "                    setedges.add((i,to))\n",
    "                    outside[to] = 1\n",
    "                    if i in outside.keys():\n",
    "                        outside[i]+=1  \n",
    "                    elif i in inside.keys():\n",
    "                        inside[i]+=1 \n",
    "                        \n",
    "                else:\n",
    "                    vertices, degrees = [], []\n",
    "                    for vertex, degree in outside.items():\n",
    "                        if vertex!=i:\n",
    "                            vertices.append(vertex)\n",
    "                            degrees.append(degree+1)\n",
    "                    s = sum(degrees)\n",
    "                    w = [x/s for x in degrees]\n",
    "                    to = choice(vertices, size=1, p=w)[0]\n",
    "                    if are_adjacent(i,to,G):\n",
    "                        to = choice(vertices, size=1, p=w)[0]\n",
    "                    G.add_edge(i,to)\n",
    "                    setedges.add((i,to))\n",
    "                    outside[to]+=1\n",
    "                    if i in outside.keys():\n",
    "                        outside[i]+=1  \n",
    "                    elif i in inside.keys():\n",
    "                        inside[i]+=1 \n",
    "                        \n",
    "            else:\n",
    "                vertices, degrees = [], []\n",
    "                for vertex, degree in inside.items():\n",
    "                    if vertex != i:\n",
    "                        vertices.append(vertex)\n",
    "                        degrees.append(degree+1)\n",
    "                s = sum(degrees)\n",
    "                w = [x/s for x in degrees]\n",
    "                to = choice(vertices, size=1, p=w)[0]\n",
    "                if are_adjacent(i,to,G):\n",
    "                    to = choice(vertices, size=1, p=w)[0]\n",
    "                G.add_edge(i,to)\n",
    "                setedges.add((i,to))\n",
    "                inside[to]+=1\n",
    "                if i in outside.keys():\n",
    "                    outside[i]+=1  \n",
    "                elif i in inside.keys():\n",
    "                    inside[i]+=1  \n",
    "    \n",
    "    F=eliminate_small_components(G)\n",
    "    return F\n",
    "                \n",
    "            \n",
    "for city in list_cities:\n",
    "    G = random_graph_3(cities_info,city,0.8, 0.6)\n",
    "    nx.write_graphml(G,'Random_Graphs_Third_Type_Corrected/Random_Graph_'+city+'.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Helper functions\n",
    "\n",
    "We work with the helper functions for the four different types of average, and for the different measures we can take from an ecosystem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------\n",
    "# Averages\n",
    "#-----------------------\n",
    "\n",
    "def quadratic(L):\n",
    "    return ( sum([x**2 for x in L])/len(L) )**0.5\n",
    "    \n",
    "def arithmetic(L):\n",
    "    return sum(L)/len(L)\n",
    "\n",
    "def geometric(L):\n",
    "    prod = 1\n",
    "    for x in L:\n",
    "        prod *=x\n",
    "    return prod**(1/len(L))\n",
    "\n",
    "def harmonic(L):\n",
    "    n = len(L)\n",
    "    sum_reciprocals = sum([1/x for x in L])\n",
    "    return n/sum_reciprocals\n",
    "\n",
    "\n",
    "mean_map = {'quadratic': quadratic, \n",
    "           'arithmetic': arithmetic, \n",
    "           'geometric': geometric, \n",
    "           'harmonic': harmonic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------\n",
    "# Graph metrics!\n",
    "#-----------------------\n",
    "\n",
    "def degree(G):\n",
    "    return np.mean([G.degree(x) for x in G.nodes()])\n",
    "\n",
    "def eccentricity(U):\n",
    "    return np.mean([nx.eccentricity(U,x) for x in U.nodes()])\n",
    "\n",
    "def clustering(U):\n",
    "    return np.mean([nx.clustering(U,x) for x in U.nodes()]) \n",
    "\n",
    "def diameter(U):\n",
    "    return nx.diameter(U)\n",
    "\n",
    "def radius(U):\n",
    "    return nx.radius(U)\n",
    "\n",
    "def avg_shortest_path_length(U):\n",
    "    return nx.average_shortest_path_length(U)\n",
    "\n",
    "def transitivity(U):\n",
    "    return nx.transitivity(U)\n",
    "\n",
    "def global_efficiency(U):\n",
    "    return nx.global_efficiency(U)\n",
    "\n",
    "def small_worldness(U):\n",
    "    return nx.algorithms.smallworld.sigma(U,niter=1,nrand=2)\n",
    "\n",
    "def rich_club_coeffs(G):\n",
    "    t_ok = True\n",
    "    t = 0\n",
    "    d = dict()\n",
    "    while t_ok:\n",
    "        nodes_large_degree=[]\n",
    "        for x in G.nodes():\n",
    "            if G.degree(x)>t:\n",
    "                nodes_large_degree.append(x)\n",
    "        core = G.subgraph(nodes_large_degree)\n",
    "        edges_core = len(core.edges())\n",
    "        nodes_core = len(core.nodes())\n",
    "        if nodes_core<=1:\n",
    "            t_ok = False\n",
    "            break\n",
    "        d[t] = (2*edges_core)/(nodes_core*(nodes_core-1))\n",
    "        t += 1 \n",
    "    return d  \n",
    "\n",
    "def max_rich_club(G):\n",
    "    rich_club=rich_club_coeffs(G)\n",
    "    max_i=0\n",
    "    \n",
    "    for i in range(len(rich_club)):\n",
    "        if rich_club[i]>rich_club[max_i]:\n",
    "            max_i=i\n",
    "    return rich_club[max_i]\n",
    "\n",
    "def core_ratio(G):\n",
    "    return len(nx.k_core(G,k=2).nodes())/len(G.nodes())\n",
    "        \n",
    "def central_point_dominance(G):\n",
    "    betwennesses = nx.betweenness_centrality(G)\n",
    "    b_max = max(betwennesses.values())\n",
    "    N = len(betwennesses.keys())\n",
    "    count = 0\n",
    "    for i, b_i in betwennesses.items():\n",
    "        count += ( b_max - b_i )/(N-1)\n",
    "    return count\n",
    "\n",
    "\n",
    "def spectral_radius(G):\n",
    "    L = nx.normalized_laplacian_matrix(G)\n",
    "    e = np.linalg.eigvals(L.A)\n",
    "    e_abs = [abs(x) for x in e]\n",
    "    return max(e_abs)\n",
    "\n",
    "def modularity(G):\n",
    "    return nx.algorithms.community.quality.performance(G,nx.algorithms.community.modularity_max.greedy_modularity_communities(G))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "metric_function_map = {'Degree': degree,\n",
    "            'Excentricidad': eccentricity,\n",
    "            'Clustering': clustering,\n",
    "            'Diámetro': diameter,\n",
    "            'Radio':radius,\n",
    "            'Camino más corto promedio':avg_shortest_path_length,\n",
    "            'Transitividad':transitivity,\n",
    "            'Eficiencia Global':global_efficiency,\n",
    "            'Rich Club Coefficient':max_rich_club,\n",
    "            'Core Ratio':core_ratio,\n",
    "            'Central Point Dominance':central_point_dominance,\n",
    "            'Spectral radius':spectral_radius,\n",
    "            'Modularidad':modularity} \n",
    "\n",
    "\n",
    "def measures(G):\n",
    "    D = dict()\n",
    "    for metric, function in metric_function_map.items():\n",
    "        D[metric] = function(nx.to_undirected(G))\n",
    "    return D\n",
    "\n",
    "def embed(D1, D2):\n",
    "    for key, value in D1.items():\n",
    "        D2[key].append(value)\n",
    "    return D2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Colaborativity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2381281213064996\n"
     ]
    }
   ],
   "source": [
    "def colaborativity(G, set_comunication, set_preparation, set_resilience, meantype):\n",
    "    '''\n",
    "    Computes the colaborativity of a network G based on sets which determine which metrics are to be computed\n",
    "    \n",
    "    - set_communication : set containing the names of the metrics that will measure communication pilar\n",
    "    - set_preparation : contains metrics that will measure preparation for future collabs pilar\n",
    "    - set_resilience : contins the names of the metrics that will measure resilience pilar\n",
    "    '''\n",
    "    comm, prep, resi = [], [], []\n",
    "    U = nx.to_undirected(G)\n",
    "    \n",
    "    for metric in set_communication:\n",
    "        comm.append( metric_function_map[metric](U) )\n",
    "    comm = arithmetic(comm)\n",
    "    \n",
    "    for metric in set_preparation:\n",
    "        prep.append( metric_function_map[metric](U) )\n",
    "    prep = arithmetic(prep)\n",
    "\n",
    "    \n",
    "    for metric in set_resilience:\n",
    "        resi.append( metric_function_map[metric](U) )\n",
    "    resi = arithmetic(resi)\n",
    "        \n",
    "    #now we compute the mean\n",
    "    \n",
    "    return mean_map[meantype]([comm, prep, resi])\n",
    "\n",
    "\n",
    "G = random_graph_3(cities_info,'GDL',0.8, 0.6)\n",
    "set_communication = {'Eficiencia Global'}\n",
    "set_preparation = {'Rich Club Coefficient'}\n",
    "set_resilience = {'Transitividad'}\n",
    "meantype = 'arithmetic'\n",
    "\n",
    "print(colaborativity(G, set_communication, set_preparation, set_resilience, meantype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colaborativity_from_dataframe(G, index, df, set_comunication, set_preparation, set_resilience, meantype):\n",
    "    '''\n",
    "    Computes the colaborativity of a network G based on sets which determine which metrics are to be computed\n",
    "    \n",
    "    - set_communication : set containing the names of the metrics that will measure communication pilar\n",
    "    - set_preparation : contains metrics that will measure preparation for future collabs pilar\n",
    "    - set_resilience : contins the names of the metrics that will measure resilience pilar\n",
    "    '''\n",
    "    comm, prep, resi = [], [], []\n",
    "    U = nx.to_undirected(G)\n",
    "    \n",
    "    for metric in set_communication:\n",
    "        comm.append( list(df[metric])[index] )\n",
    "    comm = arithmetic(comm)\n",
    "    \n",
    "    for metric in set_preparation:\n",
    "        prep.append( list(df[metric])[index] )\n",
    "    prep = arithmetic(prep)\n",
    "\n",
    "    \n",
    "    for metric in set_resilience:\n",
    "        resi.append( list(df[metric])[index] )\n",
    "    resi = arithmetic(resi)\n",
    "        \n",
    "    #now we compute the mean\n",
    "    \n",
    "    return mean_map[meantype]([comm, prep, resi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colaborativity_original(datadict):\n",
    "    '''\n",
    "    Original Collaborativity Formula during summer 2020 for project GED\n",
    "    Computes the colaborativity of a network G based on its measures, as shown below. \n",
    "    \n",
    "    Input:\n",
    "    - datadict : dictionary mapping Metric to Metric(G), for some real or synthetic graph G\n",
    "    Returns:\n",
    "    - Value between (technically) 0 and 3.5, describing the collaborativity of a graph, or network\n",
    "    \n",
    "    '''\n",
    "    Avg_deg = datadict['Degree']\n",
    "    Clus = datadict['Clustering']\n",
    "    Mod = datadict['Modularidad']\n",
    "    return (Avg_deg + Clus + - Mod ) / 3 \n",
    "\n",
    "\n",
    "\n",
    "def colaborativity_formula_1(datadict):\n",
    "    '''\n",
    "    First Proposed Collaborativity Formula in GED summer 2020 participation in the project\n",
    "    Computes the colaborativity of a network G based on its measures, as shown below. \n",
    "    \n",
    "    Input:\n",
    "    - datadict : dictionary mapping Metric to Metric(G), for some real or synthetic graph G\n",
    "    Returns:\n",
    "    - Value between (technically) 0 and 3.5, describing the collaborativity of a graph, or network\n",
    "    \n",
    "    '''\n",
    "    Efi = datadict['Eficiencia Global']\n",
    "    Tran = datadict['Transitividad']\n",
    "    Mod = datadict['Modularidad']\n",
    "    Core = datadict['Core Ratio']\n",
    "    return Efi + Tran + 1 - (Mod + Core)/2 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def colaborativity_formula_2(datadict):\n",
    "    '''\n",
    "    Second Proposed Collaborativity Formula in GED summer 2020 participation in the project\n",
    "    Computes the colaborativity of a network G based on its measures, as shown below. \n",
    "    \n",
    "    Input:\n",
    "    - datadict : dictionary mapping Metric to Metric(G), for some real or synthetic graph G\n",
    "    Returns:\n",
    "    - Value between (technically) 0 and 3, describing the collaborativity of a graph, or network\n",
    "    \n",
    "    '''\n",
    "    Efi = datadict['Eficiencia Global']\n",
    "    Tran = datadict['Transitividad']\n",
    "    Exc = datadict['Excentricidad']\n",
    "    Mod = datadict['Modularidad']\n",
    "    return Efi + Tran + (1/Exc) - Mod\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Monte Carlo Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Monte Carlo\n",
    "#----------------------\n",
    "\n",
    "tidydata = pd.read_csv('Olga/Tidy_DataFrame.csv')\n",
    "\n",
    "\n",
    "def monte_carlo_for_city(infos, city, prob_out, prob_new, num_trials, infocolab1, infocolab2):\n",
    "    data = {'Name':[],\n",
    "            'Degree':[],\n",
    "            'Eccentricity':[],\n",
    "            'clustering':[],\n",
    "            'Diámetro':[],\n",
    "            'Radio':[],\n",
    "            'Camino más corto promedio':[],\n",
    "            'Transitividad':[],\n",
    "            'Eficiencia Global':[],\n",
    "            #'Small Worldness':[],\n",
    "            'Rich Club Coefficient':[],\n",
    "            'Core Ratio':[],\n",
    "            'Central Point Dominance':[],\n",
    "            #'Spectral radius':[],\n",
    "            'Modularidad':[],\n",
    "            'Colaboratividad 1':[],\n",
    "            'Colaboratividad 2':[]} \n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        G = random_graph_3(infos,city,prob_out, prob_new)\n",
    "        U = nx.to_undirected(G)\n",
    "        \n",
    "        data['Name'].append('G'+str(i))\n",
    "        \n",
    "        data['Degree'].append( np.mean([G.degree(x) for x in G.nodes()]) )\n",
    "        data['Eccentricity'].append( np.mean([nx.eccentricity(U,x) for x in U.nodes()]) )\n",
    "        #data['clustering'].append( np.mean([nx.clustering(U,x) for x in U.nodes()]) )\n",
    "        #data['Diámetro'].append(  nx.diameter(U)  )\n",
    "        #data['Radio'].append(  nx.radius(U)  )\n",
    "        #data['Camino más corto promedio'].append( nx.average_shortest_path_length(U) )\n",
    "        data['Transitividad'].append( nx.transitivity(U) )\n",
    "        data['Eficiencia Global'].append( nx.global_efficiency(U) )\n",
    "        #data['Small Worldness'].append( nx.algorithms.smallworld.sigma(U,niter=1,nrand=2) )\n",
    "        data['Rich Club Coefficient'].append( max_rich_club(U) )\n",
    "        data['Core Ratio'].append( core_ratio(U) )\n",
    "        data['Central Point Dominance'].append(central_point_dominance(U))\n",
    "        #data['Spectral radius'].append( spectral_radius(U) )\n",
    "        data['Modularidad'].append(nx.algorithms.community.quality.performance(U,nx.algorithms.community.modularity_max.greedy_modularity_communities(U)))\n",
    "        #data['Colaboratividad 1'].append(colaborativity(G, infocolab1[0], infocolab1[1], infocolab1[2], infocolab1[3]))\n",
    "        #data['Colaboratividad 2'].append(colaborativity(G, infocolab2[0], infocolab2[1], infocolab2[2], infocolab2[3]))\n",
    "        data['Colaboratividad 1'].append(colaborativity_from_dataframe(G, i, data, infocolab1[0], infocolab1[1], infocolab1[2], infocolab1[3]))\n",
    "        data['Colaboratividad 2'].append(colaborativity_from_dataframe(G, i, data, infocolab2[0], infocolab2[1], infocolab2[2], infocolab2[3]))        \n",
    "        \n",
    "        \n",
    "    #mean of all data\n",
    "    G = random_graph_3(infos,city,prob_out, prob_new)\n",
    "    U = nx.to_undirected(G)\n",
    "    data['Name'].append('Mean')\n",
    "    data['Degree'].append( np.mean(data['Degree']) )\n",
    "    data['Eccentricity'].append( np.mean(data['Eccentricity'] ))\n",
    "    #data['clustering'].append( np.mean(data['clustering']) )\n",
    "    #data['Diámetro'].append(  np.mean(data['Diámetro'])  )\n",
    "    #data['Radio'].append(  np.mean(data['Radio'])  )\n",
    "    #data['Camino más corto promedio'].append( np.mean(data['Camino más corto promedio']) )\n",
    "    data['Transitividad'].append( np.mean(data['Transitividad']) )\n",
    "    data['Eficiencia Global'].append( np.mean(data['Eficiencia Global']) )\n",
    "    #data['Small Worldness'].append( np.mean(data['Small Worldness']) )\n",
    "    data['Rich Club Coefficient'].append( np.mean(data['Rich Club Coefficient']) )\n",
    "    data['Core Ratio'].append( np.mean(data['Core Ratio']) )\n",
    "    data['Central Point Dominance'].append(np.mean(data['Central Point Dominance']))\n",
    "    #data['Spectral radius'].append( np.mean(data['Spectral radius']) )\n",
    "    data['Modularidad'].append( np.mean(data['Modularidad']) )\n",
    "    data['Colaboratividad 1'].append( np.mean(data['Colaboratividad 1']) )\n",
    "    data['Colaboratividad 2'].append( np.mean(data['Colaboratividad 2']) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #real data\n",
    "    citydata = tidydata.loc[tidydata['Ciudad'] == city]\n",
    "        \n",
    "    data['Name'].append(city+' real')\n",
    "    data['Degree'].append( list(citydata['Degree'])[0] )\n",
    "    data['Eccentricity'].append( list(citydata['Excentricidad'])[0] )\n",
    "    #data['clustering'].append( np.mean([nx.clustering(U,x) for x in U.nodes()]) )\n",
    "    #data['Diámetro'].append(  nx.diameter(U)  )\n",
    "    #data['Radio'].append(  nx.radius(U)  )\n",
    "    #data['Camino más corto promedio'].append( nx.average_shortest_path_length(U) )\n",
    "    data['Transitividad'].append( list(citydata['Transitividad'])[0] )\n",
    "    data['Eficiencia Global'].append( list(citydata['Eficiencia Global'])[0] )\n",
    "    #data['Small Worldness'].append( citydata['Small Worldness'] )\n",
    "    data['Rich Club Coefficient'].append( list(citydata['Rich Club Coefficient'])[0] )\n",
    "    data['Core Ratio'].append( list(citydata['Core Ratio'])[0] )\n",
    "    data['Central Point Dominance'].append( list(citydata['Central Point Dominance'])[0] )\n",
    "    #data['Spectral radius'].append( 0 )\n",
    "    data['Modularidad'].append( list(citydata['Modularidad'])[0])\n",
    "    data['Colaboratividad 1'].append(colaborativity_from_dataframe(G, 0, citydata, infocolab1[0], infocolab1[1], infocolab1[2], infocolab1[3]))\n",
    "    data['Colaboratividad 2'].append(colaborativity_from_dataframe(G, 0, citydata, infocolab2[0], infocolab2[1], infocolab2[2], infocolab2[3]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #'avg strength', 'weight', 'Weighted Degree','Small Worldness','Spectral radius',\n",
    "    df = pd.DataFrame(data, columns = ['Name','Degree', 'Eccentricity', \n",
    "                                       #'clustering', 'Diámetro', 'Radio', 'Camino más corto promedio', \n",
    "                                       'Transitividad', 'Eficiencia Global',\n",
    "                                       'Rich Club Coefficient', 'Core Ratio', 'Central Point Dominance', \n",
    "                                       'Modularidad', 'Colaboratividad 1', 'Colaboratividad 2'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "infocolab1=[{'Eficiencia Global'}, {'Rich Club Coefficient'}, {'Transitividad'}, 'arithmetic']\n",
    "infocolab2=[{'Eficiencia Global'}, {'Core Ratio'}, {'Modularidad', 'Transitividad'}, 'quadratic']\n",
    "#monte_carlo_for_city(cities_info, 'Montevideo', 0.8, 0.6, 20, infocolab1, infocolab2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# Monte Carlo Cooler Version\n",
    "#----------------------------\n",
    "\n",
    "tidydata = pd.read_csv('Olga/Tidy_DataFrame.csv')\n",
    "\n",
    "def monte_carlo_2(infos, city, prob_out, prob_new, num_trials):\n",
    "    \n",
    "    data = {key : [] for key in metric_function_map.keys()}\n",
    "    data['Name'] = []\n",
    "    data['Colaboratividad Original'] = []\n",
    "    data['Colaboratividad 1'] = []\n",
    "    data['Colaboratividad 2'] = []\n",
    "    \n",
    "    \n",
    "    #Samples\n",
    "    for i in range(num_trials):\n",
    "        print(i)\n",
    "        G = random_graph_3(infos,city,prob_out, prob_new)\n",
    "        M = measures(G)\n",
    "        \n",
    "        data = embed(M,data)\n",
    "        data['Name'].append('G'+str(i))\n",
    "        data['Colaboratividad Original'].append(colaborativity_original(M))\n",
    "        data['Colaboratividad 1'].append(colaborativity_formula_1(M))\n",
    "        data['Colaboratividad 2'].append(colaborativity_formula_2(M))\n",
    "        \n",
    "    #Means\n",
    "    for key in data.keys():\n",
    "        if key != 'Name':\n",
    "            data[key].append(np.mean( data[key] ))\n",
    "    data['Name'].append('Mean')\n",
    "    \n",
    "    \n",
    "    #Real Data\n",
    "    citydata = pd.DataFrame(tidydata.loc[tidydata['Ciudad'] == city])\n",
    "    citymeasures = {metric: list(tidydata.loc[tidydata['Ciudad'] == city][metric])[0] for metric in metric_function_map.keys()}\n",
    "    \n",
    "    data = embed(citymeasures, data)\n",
    "    data['Name'].append(city+' real')\n",
    "    data['Colaboratividad Original'].append(colaborativity_original(citymeasures))\n",
    "    data['Colaboratividad 1'].append(colaborativity_formula_1(citymeasures))\n",
    "    data['Colaboratividad 2'].append(colaborativity_formula_2(citymeasures))\n",
    "\n",
    "    \n",
    "    #Incorporating the dataframe! \n",
    "    #'avg strength', 'weight', 'Weighted Degree','Small Worldness',\n",
    "    df = pd.DataFrame(data, columns = ['Name','Degree', 'Excentricidad', \n",
    "                                       'Clustering', 'Diámetro', 'Radio', 'Camino más corto promedio', \n",
    "                                       'Transitividad', 'Eficiencia Global',\n",
    "                                       'Rich Club Coefficient', 'Core Ratio', 'Central Point Dominance',\n",
    "                                       'Spectral radius', 'Modularidad', 'Colaboratividad Original', \n",
    "                                       'Colaboratividad 1', 'Colaboratividad 2'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#let's try to test this function\n",
    "#monte_carlo_2(cities_info, 'Montevideo', 0.8, 0.6, 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGS\n",
      "CABA\n",
      "CDMX\n",
      "GDL\n",
      "Pachuca\n",
      "Madrid\n",
      "Montevideo\n",
      "Oaxaca\n",
      "Sao Paulo\n",
      "Santiago\n"
     ]
    }
   ],
   "source": [
    "for city in cities_info.keys():\n",
    "    print(city)\n",
    "    df = monte_carlo_2(cities_info, city, 0.8, 0.6, 50)\n",
    "    df.to_csv('Data_Cities_wrt_50Random/Trials_'+city+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1340367487179487]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tidydata.loc[tidydata['Ciudad'] == city]['Clustering'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Transitividad</th>\n",
       "      <th>Eficiencia Global</th>\n",
       "      <th>Rich Club Coefficient</th>\n",
       "      <th>Core Ratio</th>\n",
       "      <th>Central Point Dominance</th>\n",
       "      <th>Modularidad</th>\n",
       "      <th>Colaboratividad 1</th>\n",
       "      <th>Colaboratividad 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G0</td>\n",
       "      <td>3.313953</td>\n",
       "      <td>5.534884</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.303690</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.165912</td>\n",
       "      <td>0.914049</td>\n",
       "      <td>0.247489</td>\n",
       "      <td>0.423849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G1</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.615819</td>\n",
       "      <td>0.076225</td>\n",
       "      <td>0.302647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.252322</td>\n",
       "      <td>0.903570</td>\n",
       "      <td>0.459624</td>\n",
       "      <td>0.424664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G2</td>\n",
       "      <td>3.485380</td>\n",
       "      <td>5.549708</td>\n",
       "      <td>0.043716</td>\n",
       "      <td>0.312697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.153830</td>\n",
       "      <td>0.901823</td>\n",
       "      <td>0.452138</td>\n",
       "      <td>0.439750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G3</td>\n",
       "      <td>3.296089</td>\n",
       "      <td>5.502793</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.306304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.469274</td>\n",
       "      <td>0.253046</td>\n",
       "      <td>0.907539</td>\n",
       "      <td>0.449133</td>\n",
       "      <td>0.423878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G4</td>\n",
       "      <td>3.544910</td>\n",
       "      <td>5.646707</td>\n",
       "      <td>0.043847</td>\n",
       "      <td>0.312569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538922</td>\n",
       "      <td>0.155563</td>\n",
       "      <td>0.902027</td>\n",
       "      <td>0.452139</td>\n",
       "      <td>0.451592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G5</td>\n",
       "      <td>3.247191</td>\n",
       "      <td>5.786517</td>\n",
       "      <td>0.069638</td>\n",
       "      <td>0.303498</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.460674</td>\n",
       "      <td>0.258516</td>\n",
       "      <td>0.917476</td>\n",
       "      <td>0.257712</td>\n",
       "      <td>0.427368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G6</td>\n",
       "      <td>3.182320</td>\n",
       "      <td>5.944751</td>\n",
       "      <td>0.069195</td>\n",
       "      <td>0.288027</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.458564</td>\n",
       "      <td>0.175850</td>\n",
       "      <td>0.914058</td>\n",
       "      <td>0.230185</td>\n",
       "      <td>0.422270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G7</td>\n",
       "      <td>3.213115</td>\n",
       "      <td>6.426230</td>\n",
       "      <td>0.058496</td>\n",
       "      <td>0.299679</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.486339</td>\n",
       "      <td>0.263079</td>\n",
       "      <td>0.924218</td>\n",
       "      <td>0.452725</td>\n",
       "      <td>0.435034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>G8</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.702020</td>\n",
       "      <td>0.041475</td>\n",
       "      <td>0.275461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.200645</td>\n",
       "      <td>0.925088</td>\n",
       "      <td>0.438979</td>\n",
       "      <td>0.414750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G9</td>\n",
       "      <td>3.410405</td>\n",
       "      <td>5.583815</td>\n",
       "      <td>0.068713</td>\n",
       "      <td>0.306378</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.473988</td>\n",
       "      <td>0.150561</td>\n",
       "      <td>0.892324</td>\n",
       "      <td>0.236141</td>\n",
       "      <td>0.427953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mean</td>\n",
       "      <td>3.302670</td>\n",
       "      <td>5.829324</td>\n",
       "      <td>0.055832</td>\n",
       "      <td>0.301095</td>\n",
       "      <td>0.745952</td>\n",
       "      <td>0.477382</td>\n",
       "      <td>0.202932</td>\n",
       "      <td>0.910217</td>\n",
       "      <td>0.367626</td>\n",
       "      <td>0.429111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Oaxaca real</td>\n",
       "      <td>4.375839</td>\n",
       "      <td>4.456376</td>\n",
       "      <td>0.107699</td>\n",
       "      <td>0.333850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.516779</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.480516</td>\n",
       "      <td>0.458392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name    Degree  Eccentricity  Transitividad  Eficiencia Global  \\\n",
       "0            G0  3.313953      5.534884       0.045918           0.303690   \n",
       "1            G1  3.333333      5.615819       0.076225           0.302647   \n",
       "2            G2  3.485380      5.549708       0.043716           0.312697   \n",
       "3            G3  3.296089      5.502793       0.041096           0.306304   \n",
       "4            G4  3.544910      5.646707       0.043847           0.312569   \n",
       "5            G5  3.247191      5.786517       0.069638           0.303498   \n",
       "6            G6  3.182320      5.944751       0.069195           0.288027   \n",
       "7            G7  3.213115      6.426230       0.058496           0.299679   \n",
       "8            G8  3.000000      6.702020       0.041475           0.275461   \n",
       "9            G9  3.410405      5.583815       0.068713           0.306378   \n",
       "10         Mean  3.302670      5.829324       0.055832           0.301095   \n",
       "11  Oaxaca real  4.375839      4.456376       0.107699           0.333850   \n",
       "\n",
       "    Rich Club Coefficient  Core Ratio  Central Point Dominance  Modularidad  \\\n",
       "0                0.392857    0.465116                 0.165912     0.914049   \n",
       "1                1.000000    0.457627                 0.252322     0.903570   \n",
       "2                1.000000    0.508772                 0.153830     0.901823   \n",
       "3                1.000000    0.469274                 0.253046     0.907539   \n",
       "4                1.000000    0.538922                 0.155563     0.902027   \n",
       "5                0.400000    0.460674                 0.258516     0.917476   \n",
       "6                0.333333    0.458564                 0.175850     0.914058   \n",
       "7                1.000000    0.486339                 0.263079     0.924218   \n",
       "8                1.000000    0.454545                 0.200645     0.925088   \n",
       "9                0.333333    0.473988                 0.150561     0.892324   \n",
       "10               0.745952    0.477382                 0.202932     0.910217   \n",
       "11               1.000000    0.516779                 0.435000     0.896000   \n",
       "\n",
       "    Colaboratividad 1  Colaboratividad 2  \n",
       "0            0.247489           0.423849  \n",
       "1            0.459624           0.424664  \n",
       "2            0.452138           0.439750  \n",
       "3            0.449133           0.423878  \n",
       "4            0.452139           0.451592  \n",
       "5            0.257712           0.427368  \n",
       "6            0.230185           0.422270  \n",
       "7            0.452725           0.435034  \n",
       "8            0.438979           0.414750  \n",
       "9            0.236141           0.427953  \n",
       "10           0.367626           0.429111  \n",
       "11           0.480516           0.458392  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('Data_Cities_wrt_Random/Trials_Oaxaca.csv')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
