{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing de métricas utilizando grafos sintéticos\n",
    "\n",
    "El objetivo principal de este documento es poner a prueba la coherencia o funcionalidad de cada una de las métricas de colaboración establecida y propuestas. \n",
    "\n",
    "Las herramientas con las que contamos son:\n",
    "* `Random_Graphs_Nuevas_Conexiones` : 200 grafos donde la varía la probabilidad de que una conexión vaya a un nuevo nodo\n",
    "* `Random_Graphs_Numero_Respuestas` : 200 grafos donde la varía el rango de número de respuestas que pueda dar un evaluador\n",
    "* `Random_Graphs_Rango_Respondientes` : 200 grafos donde la varía el rango de número de evaluadores, o respondientes, posibles\n",
    "* `Random_Graphs_Respondientes` : 200 grafos donde la varía la probabilidad de que una conexión vaya a un nuevo nodo\n",
    "\n",
    "### Metodología\n",
    "\n",
    "El proceso que seguiremos con cada una de las métricas de colaboración $\\mathcal{C}_{i}$ consiste en:\n",
    "* Tomar registro de cada uno de los grafos $G_{k}$\n",
    "* Para cada variación, revisar que los 50 grafos que se espera que tengan mayos índice de colaboración se encuentren en el top 100 en términos del ranking en que deja $\\mathcal{C}_{i}$ a los grafos sintéticos. \n",
    "* Se toma registro de cuántos de los 50 grafos cumplen con la condición explicada arriba.\n",
    "* Aquellas métricas cuyo registro no baje de 0.95 son razonables para continuar nuestro estudio de colaboratividad.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------\n",
    "# Importar paquetes a utilizar\n",
    "#-------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import networkx as nx\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "#in this dictionary we collect the information for the 200 random graphs we generated\n",
    "G={'Nuevas_Conexiones':[],'Numero_Respuestas':[], 'Rango_Respondientes':[], 'Respondientes':[]}\n",
    "\n",
    "for key in G.keys():\n",
    "    for i in range(200):\n",
    "        G[key].append(nx.read_graphml('Random_Graphs_'+key+'/Random_Graph_'+key+str(i)+'.graphml'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# Central point of Dominance\n",
    "#--------------------------------\n",
    "# How centralized a graph is with respect to the metric betweenness centrality.\n",
    "\n",
    "def central_point_dominance(G):\n",
    "    betwennesses = nx.betweenness_centrality(G)\n",
    "    b_max = max(betwennesses.values())\n",
    "    N = len(betwennesses.keys())\n",
    "    count = 0\n",
    "    for i, b_i in betwennesses.items():\n",
    "        count += ( b_max - b_i )/(N-1)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# Spectral Radius\n",
    "#--------------------------------\n",
    "#     the smaller the spectral radius rho, the higher the probability of 'virus infection' tau, \n",
    "#     the more difficult it is for an idea to spread in the innovative network, \n",
    "#     namely, the less efficient\n",
    "\n",
    "import numpy.linalg\n",
    "\n",
    "def spectral_radius(G):\n",
    "    L = nx.normalized_laplacian_matrix(G)\n",
    "    e = numpy.linalg.eigvals(L.A)\n",
    "    e_abs = [abs(x) for x in e]\n",
    "    return max(e_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_ratio(G):\n",
    "    return len(nx.k_core(G,k=2).nodes())/len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rich_club_coeffs(G):\n",
    "    t_ok = True\n",
    "    t = 0\n",
    "    d = dict()\n",
    "    while t_ok:\n",
    "        nodes_large_degree=[]\n",
    "        for x in G.nodes():\n",
    "            if G.degree(x)>t:\n",
    "                nodes_large_degree.append(x)\n",
    "        core = G.subgraph(nodes_large_degree)\n",
    "        edges_core = len(core.edges())\n",
    "        nodes_core = len(core.nodes())\n",
    "        if nodes_core<=1:\n",
    "            t_ok = False\n",
    "            break\n",
    "        d[t] = (2*edges_core)/(nodes_core*(nodes_core-1))\n",
    "        t += 1 \n",
    "    return d        \n",
    "\n",
    "def max_rich_club(G):\n",
    "    #rich_club_1=nx.algorithms.rich_club_coefficient(G, normalized=False)\n",
    "    rich_club=rich_club_coeffs(G)\n",
    "    max_i=0\n",
    "    for i in range(len(rich_club)):\n",
    "        if rich_club[i]>rich_club[max_i]:\n",
    "            max_i=i\n",
    "        else:\n",
    "            return rich_club[max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eccentricity(G):\n",
    "    excentricidades=nx.algorithms.distance_measures.eccentricity(G)\n",
    "    excentricidad=0\n",
    "    for i in excentricidades.keys():\n",
    "        excentricidad+=excentricidades[i]\n",
    "    return excentricidad/len(excentricidades.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_responses(G):\n",
    "    avg=0\n",
    "    respondents=0\n",
    "    for node in G.nodes:\n",
    "        try:\n",
    "            avg+= node['responses']\n",
    "            respondents+=0\n",
    "        except:\n",
    "            pass\n",
    "    if respondents==0:\n",
    "        return 0\n",
    "    return avg/respondents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree(G):\n",
    "    return 2*len(G.edges())/len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity(G):\n",
    "    return nx.algorithms.community.quality.performance(G,nx.algorithms.community.modularity_max.greedy_modularity_communities(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(G):\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for v in G.nodes():\n",
    "        if nx.degree(G,v) >= 2:          #solo el clustering coeff de nodos con deg>=2\n",
    "            total += nx.clustering(G,v)\n",
    "            count += 1\n",
    "    return total/count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion del Dataframe\n",
    "\n",
    "El siguiente bloque crea todas las metricas de la grafica que usaremos para estudiarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_function_map = {'Degree': degree,\n",
    "            'Excentricidad': eccentricity,\n",
    "            'Diametro': nx.diameter,\n",
    "            'Radio':nx.radius,\n",
    "            'Camino más corto promedio':nx.average_shortest_path_length,\n",
    "            'Transitividad':nx.transitivity,\n",
    "            'Eficiencia Global':nx.global_efficiency,\n",
    "            'Rich Club Coefficient':max_rich_club,\n",
    "            'Core Ratio':core_ratio,\n",
    "            'Central Point Dominance':central_point_dominance,\n",
    "            'Spectral radius':spectral_radius,\n",
    "            'Modularidad':modularity,\n",
    "            'Average Collaborations': avg_responses,\n",
    "            'Clustering': clustering}\n",
    "\n",
    "def measures(G):\n",
    "    D = dict()\n",
    "    for metric, function in metric_function_map.items():\n",
    "        D[metric] = [function(nx.to_undirected(G))]\n",
    "    return D\n",
    "\n",
    "def embed(D1, D2):\n",
    "    for key, value in D1.items():\n",
    "        D2[key].append(value)\n",
    "    return D2\n",
    "\n",
    "def df_colaboraciones_test(keys,n=200):\n",
    "    \"\"\"\n",
    "    keys es una lista de los atributos que queremos leer\n",
    "    \"\"\"\n",
    "\n",
    "    dfs={}\n",
    "\n",
    "    for key in keys:\n",
    "\n",
    "        for index in range(n):\n",
    "            graph=G[key][index]\n",
    "            if index==0:\n",
    "                dict_meas=measures(graph)\n",
    "            new=measures(graph)\n",
    "            for metric in metric_function_map.keys():\n",
    "                dict_meas[metric]+=new[metric]\n",
    "\n",
    "        dfs[key]=pd.DataFrame()\n",
    "        for metric in metric_function_map.keys():\n",
    "            dfs[key][metric]=dict_meas[metric]\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef df_colaboraciones_test(keys):\\n    \\n    #keys es una lista de los atributos que queremos leer\\n    \\n\\n    n=200\\n\\n    degree = {}\\n    diameter = {}\\n    radius = {}\\n    avg_shortest_path_length = {}\\n    transitivity = {}\\n    global_efficiency = {}\\n    modularity = {}\\n    rich_club_coefficient = {}\\n    core_rate= {}\\n    central_pt = {}\\n    spectral_radii = {}\\n    excentricidad = {}\\n    modularidad = {}\\n    responses = {}\\n\\n    dfs={}\\n\\n    for key in keys:\\n\\n        degree[key] = n*[0]\\n        diameter[key] = n*[0]\\n        radius[key] = n*[0]\\n        avg_shortest_path_length[key] = n*[0]\\n        transitivity[key] = n*[0]\\n        global_efficiency[key] = n*[0]\\n        modularity[key] = n*[0]\\n        rich_club_coefficient[key] = n*[0]\\n        core_rate[key]= n*[0]\\n        central_pt[key] = n*[0]\\n        spectral_radii[key] = n*[0]\\n        excentricidad[key] = n*[0]\\n        modularidad[key] = n*[0]\\n        responses[key] = n*[0]\\n\\n        for index in range(n):\\n            graph=G[key][index]\\n        \\n            #conseguimos cada parámetro para esta ciudad\\n            degree[key][index]=                        2*len(graph.edges())/len(graph.nodes())\\n            diameter[key][index] =                     nx.diameter(graph)\\n            radius[key][index] =                       nx.radius(graph)\\n            avg_shortest_path_length[key][index] =     nx.average_shortest_path_length(graph)\\n            transitivity[key][index] =                 nx.transitivity(graph)\\n            global_efficiency[key][index] =            nx.global_efficiency(graph)\\n            #modularidad precomputada\\n            rich_club_coefficient[key][index] =        max_rich_club(graph)  \\n            core_rate[key][index]=                     core_ratio(graph)\\n            central_pt[key][index]=                    central_point_dominance(graph)\\n            spectral_radii[key][index]=                spectral_radius(graph)\\n            excentricidad[key][index]=                 eccentricity(graph)\\n            modularidad[key][index]=                   nx.algorithms.community.quality.performance(graph,nx.algorithms.community.modularity_max.greedy_modularity_communities(graph))\\n            responses[key][index]=                     avg_responses(graph)\\n\\n        dfs[key]=pd.DataFrame()\\n\\n        dfs[key]['Eficiencia Global'] = global_efficiency[key]\\n        dfs[key]['Average Responses'] = responses[key]\\n        dfs[key]['Degree']= degree[key]\\n        dfs[key]['Transitividad'] = transitivity[key]\\n        dfs[key]['Modularidad'] = modularidad[key]\\n        dfs[key]['Excentricidad']= excentricidad[key]\\n        dfs[key]['Radio'] = radius[key]\\n        dfs[key]['Rich Club Coefficient'] = rich_club_coefficient[key]\\n        dfs[key]['Core Ratio'] = core_rate[key]\\n        dfs[key]['Central Point Dominance'] = [round(central_pt[key][index],3) for index in range(n)]\\n        dfs[key]['Spectral radius'] = [round(spectral_radii[key][index],3) for index in range(n)]\\n        dfs[key]['Camino más corto promedio'] = avg_shortest_path_length[key]\\n        dfs[key]['Diámetro'] = diameter[key]\\n\\n    return dfs\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def df_colaboraciones_test(keys):\n",
    "    \n",
    "    #keys es una lista de los atributos que queremos leer\n",
    "    \n",
    "\n",
    "    n=200\n",
    "\n",
    "    degree = {}\n",
    "    diameter = {}\n",
    "    radius = {}\n",
    "    avg_shortest_path_length = {}\n",
    "    transitivity = {}\n",
    "    global_efficiency = {}\n",
    "    modularity = {}\n",
    "    rich_club_coefficient = {}\n",
    "    core_rate= {}\n",
    "    central_pt = {}\n",
    "    spectral_radii = {}\n",
    "    excentricidad = {}\n",
    "    modularidad = {}\n",
    "    responses = {}\n",
    "\n",
    "    dfs={}\n",
    "\n",
    "    for key in keys:\n",
    "\n",
    "        degree[key] = n*[0]\n",
    "        diameter[key] = n*[0]\n",
    "        radius[key] = n*[0]\n",
    "        avg_shortest_path_length[key] = n*[0]\n",
    "        transitivity[key] = n*[0]\n",
    "        global_efficiency[key] = n*[0]\n",
    "        modularity[key] = n*[0]\n",
    "        rich_club_coefficient[key] = n*[0]\n",
    "        core_rate[key]= n*[0]\n",
    "        central_pt[key] = n*[0]\n",
    "        spectral_radii[key] = n*[0]\n",
    "        excentricidad[key] = n*[0]\n",
    "        modularidad[key] = n*[0]\n",
    "        responses[key] = n*[0]\n",
    "\n",
    "        for index in range(n):\n",
    "            graph=G[key][index]\n",
    "        \n",
    "            #conseguimos cada parámetro para esta ciudad\n",
    "            degree[key][index]=                        2*len(graph.edges())/len(graph.nodes())\n",
    "            diameter[key][index] =                     nx.diameter(graph)\n",
    "            radius[key][index] =                       nx.radius(graph)\n",
    "            avg_shortest_path_length[key][index] =     nx.average_shortest_path_length(graph)\n",
    "            transitivity[key][index] =                 nx.transitivity(graph)\n",
    "            global_efficiency[key][index] =            nx.global_efficiency(graph)\n",
    "            #modularidad precomputada\n",
    "            rich_club_coefficient[key][index] =        max_rich_club(graph)  \n",
    "            core_rate[key][index]=                     core_ratio(graph)\n",
    "            central_pt[key][index]=                    central_point_dominance(graph)\n",
    "            spectral_radii[key][index]=                spectral_radius(graph)\n",
    "            excentricidad[key][index]=                 eccentricity(graph)\n",
    "            modularidad[key][index]=                   nx.algorithms.community.quality.performance(graph,nx.algorithms.community.modularity_max.greedy_modularity_communities(graph))\n",
    "            responses[key][index]=                     avg_responses(graph)\n",
    "\n",
    "        dfs[key]=pd.DataFrame()\n",
    "\n",
    "        dfs[key]['Eficiencia Global'] = global_efficiency[key]\n",
    "        dfs[key]['Average Responses'] = responses[key]\n",
    "        dfs[key]['Degree']= degree[key]\n",
    "        dfs[key]['Transitividad'] = transitivity[key]\n",
    "        dfs[key]['Modularidad'] = modularidad[key]\n",
    "        dfs[key]['Excentricidad']= excentricidad[key]\n",
    "        dfs[key]['Radio'] = radius[key]\n",
    "        dfs[key]['Rich Club Coefficient'] = rich_club_coefficient[key]\n",
    "        dfs[key]['Core Ratio'] = core_rate[key]\n",
    "        dfs[key]['Central Point Dominance'] = [round(central_pt[key][index],3) for index in range(n)]\n",
    "        dfs[key]['Spectral radius'] = [round(spectral_radii[key][index],3) for index in range(n)]\n",
    "        dfs[key]['Camino más corto promedio'] = avg_shortest_path_length[key]\n",
    "        dfs[key]['Diámetro'] = diameter[key]\n",
    "\n",
    "    return dfs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colaboracion\n",
    "\n",
    "Empezamos analizando las metricas que ya hemos calculado y luego usaremos esta informacion para crear una medida de la colaboracion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have measured already\n",
    "df_colaboraciones_test(['Nuevas_Conexiones'])['Nuevas_Conexiones'].to_csv('Random_Nuevas_Conexiones.csv')\n",
    "\n",
    "#df_colaboraciones_test(['Numero_Respuestas'])['Numero_Respuestas'].to_csv('Random_Numero_Respuestas.csv')\n",
    "#df_colaboraciones_test(['Rango_Respondientes'])['Rango_Respondientes'].to_csv('Random_Rango_Respondientes.csv')\n",
    "#df_colaboraciones_test(['Respondientes'])['Respondientes'].to_csv('Random_Respondientes.csv')\n",
    "\n",
    "\n",
    "dfs = dict()\n",
    "#dfs['Nuevas_Conexiones'] = pd.read_csv('Random_Nuevas_Conexiones.csv')\n",
    "dfs['Numero_Respuestas'] = pd.read_csv('Random_Numero_Respuestas.csv')\n",
    "\n",
    "#for key in G.keys():\n",
    "#    dfs[key] = pd.read_csv('Random_'+str(key)+'.csv')\n",
    "#G={'Nuevas_Conexiones':[],'Numero_Respuestas':[], 'Rango_Respondientes':[], 'Respondientes':[]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olga/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py:765: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/olga/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py:706: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'fit_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-384e73a86c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnormalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mprin_comp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'fit_transform'"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------\n",
    "#Preparar escalas y herramientas para el analisis.\n",
    "#---------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X={}\n",
    "normalized={}\n",
    "pca={}\n",
    "prin_comp={}\n",
    "\n",
    "for key in G.keys():\n",
    "    X[key]=dfs[key].to_numpy()\n",
    "\n",
    "    normalized[key]= StandardScaler().fit_transform(X[key])\n",
    "    pca[key]=PCA(n_components=5)\n",
    "    prin_comp[key]=pca.fit_transform(normalized[key])\n",
    "\n",
    "    print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevas_Conexiones\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Nuevas_Conexiones'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f70538410a82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprin_comp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprin_comp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Nuevas_Conexiones'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for key in G.keys():\n",
    "    print(key)\n",
    "    plt.scatter(prin_comp[key][:,0], prin_comp[key][:,1],color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Formulas de Colaboracion\"\"\"\n",
    "\n",
    "def colaborativity_formula_0(df):\n",
    "    '''\n",
    "    Original Collaborativity Formula during summer 2020 for project GED.\n",
    "    Computes the colaborativity of a network G based on its measures, as shown below. \n",
    "    \n",
    "    Input:\n",
    "    - df : dataframe mapping each city to its graph metrics\n",
    "    Returns:\n",
    "    - Value describing the collaborativity of a graph, or network\n",
    "    '''\n",
    "    Avg_colabs =df['Average Collaborations']\n",
    "    Clust = df['Clustering']\n",
    "    Mod = df['Modularidad']\n",
    "    print(Avg_colabs, Clust, Mod)\n",
    "    return (1/2) * Avg_colabs * (Clust + (np.log10(Mod**2)*-1))\n",
    "\n",
    "\n",
    "def colaborativity_formula_1(df):\n",
    "    Efi = df['Eficiencia Global']\n",
    "    Tran = df['Transitividad']\n",
    "    Mod = df['Modularidad']\n",
    "    Core = df['Core Ratio']\n",
    "    return Efi + Tran + 1 - (Mod + Core)/2 \n",
    "\n",
    "\n",
    "def colaborativity_formula_2(df):\n",
    "    Efi = df['Eficiencia Global']\n",
    "    Tran = df['Transitividad']\n",
    "    Exc = df['Excentricidad']\n",
    "    Mod = df['Modularidad']\n",
    "    return Efi + Tran + (1/Exc) - Mod\n",
    "\n",
    "\n",
    "def colaborativity_formula_3(df):\n",
    "    efi = df['Eficiencia Global']   #comunicacion\n",
    "    clus = df['Clustering']         #robustez\n",
    "    mod = df['Modularidad']          #preparación para el futuro \n",
    "    return (efi * clus * (1+np.cos(math.pi*mod)) /2 )**(1/3)\n",
    "\n",
    "\n",
    "def colaborativity_formula_4(df):\n",
    "    efi = df['Eficiencia Global']    #comunicacion \n",
    "    tran = df['Transitividad']       #robustez\n",
    "    mod = df['Modularidad']           #preparación para el futuro \n",
    "    return (efi * tran * (1+np.cos(math.pi*mod)) /2 )**(1/3)\n",
    "\n",
    "\n",
    "def colaborativity_formula_5(df):\n",
    "    efi = df['Eficiencia Global']    #comunicacion \n",
    "    tran = df['Transitividad']       #robustez\n",
    "    core = df['Core Ratio']           #preparación para el futuro \n",
    "    return efi + tran + 1 - core \n",
    "\n",
    "\n",
    "def colaborativity_formula_6(df):\n",
    "    efi = df['Eficiencia Global']    #comunicacion \n",
    "    tran = df['Transitividad']       #robustez\n",
    "    exc = df['Excentricidad']        #preparación para el futuro \n",
    "    return (efi * tran * (np.sin(math.pi/exc)) )**(1/3)\n",
    "\n",
    "\n",
    "# N e w    i d e a s    f o r   f o r m u l a s #\n",
    "\n",
    "def colaborativity_formula_7(df):\n",
    "    avg_deg = df['Average Collaborations']  #1 cantidad  \n",
    "    efi = df['Eficiencia Global']    #2 calidad   comunicacion \n",
    "    tran = df['Transitividad']       #            robustez\n",
    "    exc = df['Excentricidad']        #preparación para el futuro \n",
    "    return 0.5*(np.log10(avg_deg+1)/np.log10(26))  +  0.5*quadratic([efi , tran , (np.sin(math.pi/exc))])\n",
    "\n",
    "\n",
    "def colaborativity_formula_8(df):\n",
    "    avg_deg = df['Average Collaborations']  #1 cantidad  \n",
    "    efi = df['Eficiencia Global']    #2 calidad   comunicacion \n",
    "    tran = df['Transitividad']       #            robustez\n",
    "    mod = df['Modularidad']        #preparación para el futuro \n",
    "    return 0.5*(np.log10(avg_deg+1)/np.log10(26)) + 0.5*quadratic([efi , tran , 0.5*(1+np.cos(math.pi*mod)) ])\n",
    "\n",
    "\n",
    "def colaborativity_formula_9(df):\n",
    "    avg_deg = df['Average Collaborations']  #1 cantidad  \n",
    "    efi = df['Eficiencia Global']    #2 calidad   comunicacion \n",
    "    tran = df['Transitividad']       #            robustez\n",
    "    rcc = df['Rich Club Coefficient']        #preparación para el futuro \n",
    "    core = df['Core Ratio']        #preparación para el futuro \n",
    "    return 0.5*(np.log10(avg_deg+1)/np.log10(26)) + 0.5*quadratic([efi , tran , (rcc*core)**0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "196    0\n",
      "197    0\n",
      "198    0\n",
      "199    0\n",
      "200    0\n",
      "Name: Average Collaborations, Length: 201, dtype: int64 0      0.107611\n",
      "1      0.107611\n",
      "2      0.078328\n",
      "3      0.122141\n",
      "4      0.075946\n",
      "         ...   \n",
      "196    0.073529\n",
      "197    0.068112\n",
      "198    0.093461\n",
      "199    0.089974\n",
      "200    0.083232\n",
      "Name: Clustering, Length: 201, dtype: float64 0     NaN\n",
      "1     NaN\n",
      "2     NaN\n",
      "3     NaN\n",
      "4     NaN\n",
      "       ..\n",
      "196   NaN\n",
      "197   NaN\n",
      "198   NaN\n",
      "199   NaN\n",
      "200   NaN\n",
      "Name: Modularidad, Length: 201, dtype: float64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-c837b8dca603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mcolab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder_colab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mratio\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: nan"
     ]
    }
   ],
   "source": [
    "#---------------------------------------\n",
    "# Fórmula para colaboratividad\n",
    "#---------------------------------------\n",
    "\n",
    "\n",
    "colaborativity_formulas={}\n",
    "for i in range(10):\n",
    "    colaborativity_formulas[i]=eval('colaborativity_formula_'+str(i))\n",
    "\n",
    "for key in dfs.keys():\n",
    "    for i in range(10):\n",
    "        colab={}\n",
    "        colaboration_results = colaborativity_formulas[i](dfs[key])\n",
    "\n",
    "        #each varying parameter name maps\n",
    "        #to a dictionary showing the collaboration i results\n",
    "        #in the corresponding 200 graphs\n",
    "        colab[key] = {colaboration_results[x]:x for x in range(200)} \n",
    "        order_colab=list(colab[key].keys())\n",
    "        order_colab.sort()\n",
    "        ratio=0\n",
    "        for i in range(40):\n",
    "            if colab[order_colab[i]]<101:\n",
    "                ratio+=1\n",
    "                \n",
    "        print('')\n",
    "        print(ratio/40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    print(colab[order_colab[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
